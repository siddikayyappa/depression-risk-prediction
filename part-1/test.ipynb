{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from fasttext import FastText\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = FastText.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    def __init__(self, model) -> None:\n",
    "        self.model = model\n",
    "    def get_embeddings(self, words):\n",
    "        return np.array([self.model.get_word_vector(i) for i in words])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pkl.load(open('./tags.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_class = Embeddings(model)\n",
    "ems = embedding_class.get_embeddings(tags[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "anew_dataset = pd.read_csv('./warriner_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "anew_dict= dict()\n",
    "words = anew_dataset['term']\n",
    "valence_ratings = anew_dataset['pleasure']\n",
    "arousal_ratings = anew_dataset['arousal']\n",
    "word_embeddings = embedding_class.get_embeddings(words)\n",
    "word_embedding_dict = dict(zip(words, word_embeddings))\n",
    "for i in range(len(words)):\n",
    "    anew_dict[words[i]] = [valence_ratings[i], arousal_ratings[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = word_embeddings\n",
    "Y = np.array([anew_dict[i] for i in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.26, 2.41],\n",
       "       [5.3 , 2.65],\n",
       "       [2.84, 3.73],\n",
       "       ...,\n",
       "       [7.  , 5.63],\n",
       "       [5.86, 5.68],\n",
       "       [6.3 , 4.18]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           aardvark\n",
       "1            abalone\n",
       "2            abandon\n",
       "3        abandonment\n",
       "4              abbey\n",
       "            ...     \n",
       "13909           zone\n",
       "13910         zoning\n",
       "13911            zoo\n",
       "13912           zoom\n",
       "13913       zucchini\n",
       "Name: term, Length: 13914, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03986298,  0.00379052, -0.0127756 , ..., -0.01078152,\n",
       "        -0.02300994,  0.0079215 ],\n",
       "       [ 0.02610103,  0.01788571,  0.00896458, ...,  0.0547346 ,\n",
       "         0.02627475,  0.02617722],\n",
       "       [-0.01662364, -0.06317363,  0.10360997, ..., -0.00658366,\n",
       "        -0.00859841, -0.0122865 ],\n",
       "       ...,\n",
       "       [ 0.01154633,  0.02386309,  0.02965424, ...,  0.02644203,\n",
       "         0.09439246,  0.01073311],\n",
       "       [ 0.01526884, -0.06252627,  0.06748683, ..., -0.06219679,\n",
       "        -0.09277178, -0.06651503],\n",
       "       [ 0.04610313,  0.01816115,  0.03932561, ..., -0.00771078,\n",
       "        -0.03635433,  0.0058565 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = Y/9\n",
    "# SCaling the data -- large loss issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69555556, 0.26777778],\n",
       "       [0.58888889, 0.29444444],\n",
       "       [0.31555556, 0.41444444],\n",
       "       ...,\n",
       "       [0.77777778, 0.62555556],\n",
       "       [0.65111111, 0.63111111],\n",
       "       [0.7       , 0.46444444]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03986298,  0.00379052, -0.0127756 , ..., -0.01078152,\n",
       "        -0.02300994,  0.0079215 ],\n",
       "       [ 0.02610103,  0.01788571,  0.00896458, ...,  0.0547346 ,\n",
       "         0.02627475,  0.02617722],\n",
       "       [-0.01662364, -0.06317363,  0.10360997, ..., -0.00658366,\n",
       "        -0.00859841, -0.0122865 ],\n",
       "       ...,\n",
       "       [ 0.01154633,  0.02386309,  0.02965424, ...,  0.02644203,\n",
       "         0.09439246,  0.01073311],\n",
       "       [ 0.01526884, -0.06252627,  0.06748683, ..., -0.06219679,\n",
       "        -0.09277178, -0.06651503],\n",
       "       [ 0.04610313,  0.01816115,  0.03932561, ..., -0.00771078,\n",
       "        -0.03635433,  0.0058565 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(X, open('X.pkl', 'wb'))\n",
    "pkl.dump(Y, open('Y.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(300, 150)\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 100),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 10),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.output = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.linear_stack(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 0.06684678047895432, Test Loss: 0.050760380923748016\n",
      "Epoch 1, Training Loss: 0.04263759031891823, Test Loss: 0.03243699297308922\n",
      "Epoch 2, Training Loss: 0.04355083405971527, Test Loss: 0.0219583697617054\n",
      "Epoch 3, Training Loss: 0.028956186026334763, Test Loss: 0.01788204535841942\n",
      "Epoch 4, Training Loss: 0.018020866438746452, Test Loss: 0.01957821100950241\n",
      "Epoch 5, Training Loss: 0.01165289618074894, Test Loss: 0.011968214064836502\n",
      "Epoch 6, Training Loss: 0.0043008956126868725, Test Loss: 0.01163704227656126\n",
      "Epoch 7, Training Loss: 0.014549708925187588, Test Loss: 0.010042461566627026\n",
      "Epoch 8, Training Loss: 0.009714298881590366, Test Loss: 0.004884866066277027\n",
      "Epoch 9, Training Loss: 0.007247136440128088, Test Loss: 0.00761767290532589\n",
      "Epoch 10, Training Loss: 0.005845861509442329, Test Loss: 0.007925717160105705\n",
      "Epoch 11, Training Loss: 0.005826178006827831, Test Loss: 0.00807410292327404\n",
      "Epoch 12, Training Loss: 0.007616942748427391, Test Loss: 0.009172054938971996\n",
      "Epoch 13, Training Loss: 0.006392224226146936, Test Loss: 0.005650630220770836\n",
      "Epoch 14, Training Loss: 0.008355202153325081, Test Loss: 0.009417381137609482\n",
      "Epoch 15, Training Loss: 0.011155904270708561, Test Loss: 0.00740538677200675\n",
      "Epoch 16, Training Loss: 0.004220973700284958, Test Loss: 0.007977397181093693\n",
      "Epoch 17, Training Loss: 0.005531032104045153, Test Loss: 0.007061885669827461\n",
      "Epoch 18, Training Loss: 0.006447554100304842, Test Loss: 0.007892965339124203\n",
      "Epoch 19, Training Loss: 0.009938583709299564, Test Loss: 0.006027573253959417\n",
      "Epoch 20, Training Loss: 0.009006131440401077, Test Loss: 0.014880611561238766\n",
      "Epoch 21, Training Loss: 0.008308937773108482, Test Loss: 0.007040234282612801\n",
      "Epoch 22, Training Loss: 0.00760415755212307, Test Loss: 0.011058212257921696\n",
      "Epoch 23, Training Loss: 0.007758721709251404, Test Loss: 0.00969719048589468\n",
      "Epoch 24, Training Loss: 0.00928375031799078, Test Loss: 0.004272457677870989\n",
      "Epoch 25, Training Loss: 0.006177007686346769, Test Loss: 0.008059816434979439\n",
      "Epoch 26, Training Loss: 0.005555975716561079, Test Loss: 0.006804746575653553\n",
      "Epoch 27, Training Loss: 0.007843884639441967, Test Loss: 0.011366420425474644\n",
      "Epoch 28, Training Loss: 0.004980819765478373, Test Loss: 0.011591528542339802\n",
      "Epoch 29, Training Loss: 0.007847064174711704, Test Loss: 0.0078047337010502815\n",
      "Epoch 30, Training Loss: 0.008570662699639797, Test Loss: 0.008366411551833153\n",
      "Epoch 31, Training Loss: 0.0088858213275671, Test Loss: 0.007956581190228462\n",
      "Epoch 32, Training Loss: 0.008481106720864773, Test Loss: 0.00697675533592701\n",
      "Epoch 33, Training Loss: 0.004030637443065643, Test Loss: 0.00837559811770916\n",
      "Epoch 34, Training Loss: 0.004834597930312157, Test Loss: 0.009511684067547321\n",
      "Epoch 35, Training Loss: 0.008012542501091957, Test Loss: 0.0041168127208948135\n",
      "Epoch 36, Training Loss: 0.007432162296026945, Test Loss: 0.006491119507700205\n",
      "Epoch 37, Training Loss: 0.005410533398389816, Test Loss: 0.010380121879279613\n",
      "Epoch 38, Training Loss: 0.005278658587485552, Test Loss: 0.013626168482005596\n",
      "Epoch 39, Training Loss: 0.00723773380741477, Test Loss: 0.006936944555491209\n",
      "Epoch 40, Training Loss: 0.006935575511306524, Test Loss: 0.009217946790158749\n",
      "Epoch 41, Training Loss: 0.009981461800634861, Test Loss: 0.005317205563187599\n",
      "Epoch 42, Training Loss: 0.004694774746894836, Test Loss: 0.006031997036188841\n",
      "Epoch 43, Training Loss: 0.004401227459311485, Test Loss: 0.011737587861716747\n",
      "Epoch 44, Training Loss: 0.008698465302586555, Test Loss: 0.008474624715745449\n",
      "Epoch 45, Training Loss: 0.007147612981498241, Test Loss: 0.016136962920427322\n",
      "Epoch 46, Training Loss: 0.009860878810286522, Test Loss: 0.005055437795817852\n",
      "Epoch 47, Training Loss: 0.00792789924889803, Test Loss: 0.007262812461704016\n",
      "Epoch 48, Training Loss: 0.007067810278385878, Test Loss: 0.010205525904893875\n",
      "Epoch 49, Training Loss: 0.006374842952936888, Test Loss: 0.007919197902083397\n",
      "Epoch 50, Training Loss: 0.007840664125978947, Test Loss: 0.006359959952533245\n",
      "Epoch 51, Training Loss: 0.009062089957296848, Test Loss: 0.015387165360152721\n",
      "Epoch 52, Training Loss: 0.006186653394252062, Test Loss: 0.006505819037556648\n",
      "Epoch 53, Training Loss: 0.005742624402046204, Test Loss: 0.008381186053156853\n",
      "Epoch 54, Training Loss: 0.006437556352466345, Test Loss: 0.009327995590865612\n",
      "Epoch 55, Training Loss: 0.006549022626131773, Test Loss: 0.008762659505009651\n",
      "Epoch 56, Training Loss: 0.006489048711955547, Test Loss: 0.006388776935636997\n",
      "Epoch 57, Training Loss: 0.008130718022584915, Test Loss: 0.006895522121340036\n",
      "Epoch 58, Training Loss: 0.004920102655887604, Test Loss: 0.008500722236931324\n",
      "Epoch 59, Training Loss: 0.0058341617695987225, Test Loss: 0.013159696944057941\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if(train == True):\n",
    "    best_loss = 10000\n",
    "    model_train = NetworkModel().to(device)\n",
    "    best_model = model_train.state_dict()\n",
    "    epochs = 60\n",
    "    learning_rate = 16e-5\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model_train.parameters(), lr=learning_rate)\n",
    "    test_loss = []\n",
    "    train_loss = []\n",
    "    for i in range(epochs):\n",
    "        for X, Y in train_loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            Y_pred = model_train(X.float())\n",
    "            loss = loss_fn(Y_pred, Y.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        # Test Loss\n",
    "        with torch.no_grad():\n",
    "            for X, Y in test_loader:\n",
    "                X, Y = X.to(device), Y.to(device)\n",
    "                Y_pred = model_train(X.float())\n",
    "                test_loss_fn = loss_fn(Y_pred, Y.float())\n",
    "            print(f'Epoch {i}, Training Loss: {loss.item()}, Test Loss: {test_loss_fn.item()}')\n",
    "            test_loss.append(test_loss_fn.item())\n",
    "            if(test_loss_fn.item() < best_loss):\n",
    "                best_loss = test_loss_fn.item()\n",
    "                best_model = model_train.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss[:], label='Training Loss')\n",
    "plt.plot(test_loss[:], label='Test Loss')\n",
    "plt.legend()\n",
    "datestring = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "plt.title(datestring)\n",
    "plt.savefig(f'./train_logs/{datestring}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in range(len(X_test)):\n",
    "    X_out = model_train(X_test[i].float())\n",
    "    # print(X_out)\n",
    "    Y_out= y_test[i]\n",
    "    # print(Y_out)\n",
    "    array.append((sum((X_out - Y_out)**2)))\n",
    "    # array.append(loss_fn(X_out, Y_out).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "torch.mean(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(7.9262e-07, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.9129e-06, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.6160e-06, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.3958e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.5100e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.7761e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.7996e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.1430e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.2514e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.7277e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(4.0171e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(5.3096e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(5.4564e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(6.4358e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(6.4402e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.4267e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.5749e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.7187e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.9123e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.1020e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.4422e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.9288e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " ...]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006952543277293444"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0041168127208948135"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = NetworkModel()\n",
    "new_model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20046612083439563, 0.18230265347225605, 0.16290003632501426, 0.15127444118333783, 0.14773261097865975, 0.13832314989364072, 0.12533755131575616, 0.12278560870142934, 0.11918393400656563, 0.11901204270457105, 0.11750983957512642, 0.1142529720617568, 0.10664505614225023, 0.10631713113045319, 0.10447450239504284, 0.10052420478327359, 0.09899732188821747, 0.0985560273665261, 0.09700937702653742, 0.09632014177828949, 0.0948912426381513, 0.09428158183486657, 0.09368346492229337, 0.09340462645651454, 0.09221900501746641, 0.089615642349304, 0.08945062745740148, 0.08918755649278629, 0.08801293927734603, 0.08797380307190467, 0.08674019073173528, 0.08597606834623915, 0.0851456885468848, 0.08504816800045911, 0.08396749868331524, 0.08380619286645526, 0.08333772184534835, 0.08174679459584684, 0.07961691873838411, 0.07954165028393693, 0.07860631223824951, 0.07833092123469837, 0.0781473914468418, 0.07807984947639929, 0.07719480739581996, 0.07694520875478972, 0.07665020312438461, 0.07652369084824033, 0.07620148921874652, 0.07613246930079304, 0.07590541751196755, 0.07552281284347445, 0.07526788082729646, 0.0749293999411315, 0.0736540574870863, 0.07306755403247624, 0.07289835569270026, 0.07201089642822003, 0.07071882909215417, 0.07034714720989062, 0.06950105993548421, 0.0694128135998095, 0.06928608730694397, 0.06922231086671932, 0.06918874324571393, 0.06912971771181657, 0.0690148698309351, 0.06871011610138224, 0.06848061449694773, 0.06785529932443152, 0.06779147596974182, 0.06745804036832972, 0.06672046428435904, 0.06599955352606399, 0.0655162884190849, 0.06548681039229884, 0.06444903055597759, 0.0630183168412673, 0.0630085088449612, 0.06299554151528067, 0.0626701306474277, 0.06265582508606767, 0.06260471139400653, 0.06196414485284756, 0.06188493707298576, 0.06179425896546729, 0.061374907372088, 0.06123174805933156, 0.06117332568631813, 0.06102604218549589, 0.060958929610988394, 0.06088778503968484, 0.060674797825528155, 0.06060737927430769, 0.06029148203488854, 0.06000381676470591, 0.05987220136425664, 0.05985379268682805, 0.05963656897251246, 0.05958959129539785, 0.05957475057605818, 0.05926357903476548, 0.059153410562775975, 0.059049703741025555, 0.058787544460793366, 0.058769854642789575, 0.058442492999952064, 0.058152115592749645, 0.057947247772705775, 0.05792919959469423, 0.057457334822350326, 0.057407833303204515, 0.0573158478256342, 0.05720366030887933, 0.057132147496645885, 0.05709951986475173, 0.05707676718566945, 0.056825412510315636, 0.0566281431609301, 0.056551723493504284, 0.05605907206441457, 0.05598320556312265, 0.055967264039563154, 0.05558110160885471, 0.0554820919909735, 0.055156616695497734, 0.05496944728610173, 0.054878145257802824, 0.05473904225061131, 0.05460922403340937, 0.05456400279549012, 0.05440525668204911, 0.05428511429097527, 0.05415137055589666, 0.054137470486855015, 0.05398292571366966, 0.05383489808325652, 0.053825986417724916, 0.05376489605335498, 0.05374783699551755, 0.05369809044391785, 0.05341893202041499, 0.053284330103457164, 0.05299397897757365, 0.05281826554357853, 0.05281326312212127, 0.05274457693132696, 0.05255974060931837, 0.05237837839216595, 0.0522711075608253, 0.05226450653131675, 0.052087574151717594, 0.05189472521376728, 0.05179313894558826, 0.051620266831781066, 0.051565682050597465, 0.051392164983235324, 0.051277543039189216, 0.05119301117169902, 0.051174393407497444, 0.05108143283796944, 0.05105595309376672, 0.05104418377904091, 0.05088147378869089, 0.05052721969573063, 0.050274714958816566, 0.05017653424778896, 0.050122325975052166, 0.04998196240672285, 0.04990671507204303, 0.0497880286093211, 0.04969881529208705, 0.049607042023410715, 0.049000574573956276, 0.0489929401779244, 0.04893785047492075, 0.0485995960748317, 0.048558261917480874, 0.04846267528047382, 0.04824472529342638, 0.04813267829806897, 0.047509551078798264, 0.047472008925881104, 0.04737789820018638, 0.04730397113895666, 0.047095828939234356, 0.04708658545691614, 0.047018105134735005, 0.04694430535179766, 0.04691258494108376, 0.046848001221042546, 0.0468311482614572, 0.046787808592380555, 0.04651524234542686, 0.046496945250306905, 0.04599685063415469, 0.045959958886125946, 0.045925772862406816, 0.04583902670107097, 0.04583877047382734, 0.04580485705450052, 0.045571025429691284, 0.045507366167293006, 0.04543131720955052, 0.04541428811545863, 0.045324553940555415, 0.045118156372922484, 0.04508604908095103, 0.044794889157813156, 0.04477915091073775, 0.04473022471877415, 0.04439855788495724, 0.044374411701460344, 0.044307454858228644, 0.0442274361191268, 0.04420601754007349, 0.04394811104391279, 0.043925109240413825, 0.043743186904652245, 0.043729638260826695, 0.043503114602775866, 0.043398974145647085, 0.04326657912285453, 0.043221752175527275, 0.043174953730847544, 0.0430197275233757, 0.04290464837530961, 0.0426664514876159, 0.04264245388700717, 0.04263005641547702, 0.04260464507860329, 0.04258530607430657, 0.0424368402023325, 0.04240346732264826, 0.04235539680428195, 0.042278983154457994, 0.0420088911416597, 0.04197405296569053, 0.041942315037614045, 0.04187074843961585, 0.04186869622254168, 0.04176946581832107, 0.04174048246259908, 0.04167665440445109, 0.04156090657585213, 0.04150200682380607, 0.04126153256984297, 0.041166830690733146, 0.04067943536297423, 0.040584560754032765, 0.04052964094106064, 0.040498639061065315, 0.04041552234316849, 0.04039851052305009, 0.04030888281218105, 0.040278298920975744, 0.040203279697566964, 0.04014070396252119, 0.04009680152526293, 0.0400215757438693, 0.03999176956041003, 0.03998442523562583, 0.039969158785306845, 0.03982456476021222, 0.03961064212536679, 0.03952789150184448, 0.039517647411674205, 0.039383024686191155, 0.03926620834165106, 0.039057735054088695, 0.03903890625202914, 0.03903877621466673, 0.03902601618494291, 0.03894509813644376, 0.038856783519566736, 0.03870430992519511, 0.03864119067088922, 0.038618059640043494, 0.03839461557193141, 0.038312461818205856, 0.038283498483382195, 0.03819984162122674, 0.0381917132044165, 0.03818592151176394, 0.03811758477326356, 0.038032717901350536, 0.038008985713966235, 0.03793513468487525, 0.03785472756465264, 0.037797717328943055, 0.037626389123429395, 0.03759097919705104, 0.03757328089709378, 0.037524898538344, 0.03751399120815903, 0.03746148548385635, 0.037443384913880634, 0.03741625037064354, 0.03741407333109255, 0.03728217050342755, 0.03728160894184381, 0.03718312322739965, 0.03706106990456106, 0.03704157470328154, 0.036996860418451245, 0.03693913404811964, 0.03693594964255804, 0.03657418641524643, 0.03653636408728665, 0.0364513384543783, 0.03638102204311704, 0.036245074327072864, 0.036117324443651184, 0.03606448555858714, 0.03580283375002635, 0.03578397164259976, 0.035578992436717714, 0.03554751320090512, 0.03549774478330386, 0.03548263722757427, 0.03544922951387302, 0.03537024696280548, 0.03529739295333223, 0.03527719090839673, 0.03507248606413805, 0.0350415429798907, 0.035018821458533515, 0.03498207573991584, 0.03494271322046481, 0.034889909412788175, 0.034880038375138256, 0.034859543909272504, 0.03479759089477183, 0.03465036680224523, 0.034526776028374714, 0.03450946864809384, 0.0339895254275226, 0.03390428929725735, 0.03388846521431371, 0.03386827230072866, 0.03378837502209444, 0.03367558014652142, 0.03357934459437757, 0.033554311934687206, 0.033516289701693035, 0.033110180949176775, 0.03309585493619541, 0.033081224689198045, 0.03299695420379265, 0.032877150708320944, 0.03272101371680743, 0.03271601909991848, 0.032644396761359745, 0.03257416468130771, 0.03257257617469033, 0.03251634378951436, 0.03249792737600694, 0.0324657190505932, 0.03246299685480854, 0.03240703687959831, 0.032390420609003844, 0.03235478168414457, 0.03229555474955537, 0.032216955120160526, 0.032164586650045866, 0.03216058428112518, 0.03214606228831628, 0.032141051095095394, 0.032069891595037155, 0.03197989226697179, 0.03197426444636232, 0.03186557860164704, 0.03183375839333006, 0.031775296199690134, 0.031673058702759105, 0.03156002892824808, 0.03152258792053386, 0.031401797988677156, 0.03123250480305664, 0.0312178097847878, 0.031142038859313423, 0.031077715041190706, 0.03105663637102348, 0.031044886061741064, 0.030966296839858597, 0.03095714731682963, 0.030953962851776727, 0.03095072079845938, 0.030916431753007928, 0.030859254150580114, 0.030849254183831464, 0.030844730784107193, 0.03072201636507424, 0.030721016718343843, 0.030709476767122795, 0.03063614255945248, 0.030540449843416077, 0.030535189041363216, 0.030518517003045607, 0.030515610913687274, 0.03042505024808403, 0.0303832120777635, 0.03026169545950924, 0.030171385962590176, 0.030141381620523724, 0.030123690839230617, 0.030099597582758077, 0.030077169167844513, 0.030074235120341845, 0.03005808342283928, 0.02996849224433317, 0.029828924986218648, 0.029788218467807673, 0.029763558682158388, 0.02975249059426486, 0.029681702425644448, 0.029640433771986708, 0.029627027203491512, 0.02962243842297897, 0.029618021695498594, 0.029599767613392156, 0.029477983168089573, 0.02937192919552518, 0.02930019252360677, 0.02929904099916954, 0.029211264576118015, 0.029205222933261978, 0.029196345284183696, 0.02918322978583655, 0.029161256464985807, 0.02915308472483448, 0.029048622509598828, 0.029022809321535982, 0.02901298732774494, 0.029007275923153122, 0.028980164321895045, 0.02895608994563883, 0.02888654736863322, 0.028868063882318988, 0.028851257271710434, 0.028789860594526772, 0.028762943886545246, 0.028642487611661795, 0.02859057174026162, 0.02857786934750535, 0.028529496938192924, 0.028501699739583698, 0.028418854379788104, 0.02841403030088989, 0.028377417601257837, 0.028358143915895147, 0.028337248927613162, 0.028336525633242956, 0.02833002343564576, 0.02828186503192451, 0.028269636632500643, 0.028237525118869292, 0.028188103961136156, 0.02817062851281827, 0.028158920056734767, 0.028153038377502944, 0.02813771609822801, 0.02803655517513722, 0.027955076071126458, 0.02793913772595337, 0.027937133567579132, 0.0279180372660135, 0.02790451734881428, 0.027840760629154283, 0.02780711465172994, 0.027663778586433145, 0.02762837238140957, 0.027595870442516296, 0.027584504154804186, 0.02755433537083096, 0.027488504484058346, 0.027463725068694555, 0.027392849801729673, 0.027372185546649705, 0.02723376133011507, 0.027156664142097935, 0.026938972186587612, 0.026872110571903814, 0.026857269606141675, 0.026833623024436364, 0.02681903175417942, 0.026804643662315907, 0.02675469984055297, 0.026736547322705872, 0.026728611734546194, 0.026612483581041367, 0.026599566979520324, 0.026569158980993636, 0.026462212502527, 0.02643343758974233, 0.02639054523084227, 0.026373608372644745, 0.0263511119704298, 0.026343138353305647, 0.026249325131256766, 0.026238181264602402, 0.026233800452798477, 0.026154874178894894, 0.026136465084980093, 0.026132453861878832, 0.026123446589597362, 0.02610043522387513, 0.026017132540885987, 0.02594673395180999, 0.02591479578211475, 0.02572516323310536, 0.025653468018763503, 0.025607190232234085, 0.025593081020216367, 0.025567217063406502, 0.025543508585889007, 0.025486142160744053, 0.025479066994873376, 0.025451424562756245, 0.025450112014848997, 0.025438886560329377, 0.025417380397805965, 0.025371498052155193, 0.025336111942582354, 0.02529238761296067, 0.025274786934899207, 0.025266747396125437, 0.025261894822769772, 0.02525154215423154, 0.025244127029672145, 0.025218712258291285, 0.025217674746103612, 0.02520422179936422, 0.025199714076573072, 0.025165566304413432, 0.025157995490657198, 0.025147064267365737, 0.025138199337828217, 0.025129321895747445, 0.025124682864578786, 0.02495920843241824, 0.02493154567198492, 0.02490989209793982, 0.02488980106679909, 0.024805192870370522, 0.02477807415042371, 0.024770749500016866, 0.024640666067030227, 0.02460248288684808, 0.0245715094621025, 0.02456998329199214, 0.024497739386704652, 0.02448790767836442, 0.02440042391498346, 0.02428799226676165, 0.024275179897265985, 0.02424961467795872, 0.024235194461058904, 0.024226177395390514, 0.024139807322159867, 0.024139046593870634, 0.024105010366924126, 0.024060771103902156, 0.024059645965014365, 0.02403201941980635, 0.02402395193572262, 0.023954502169264764, 0.02394629230088305, 0.023946190749954965, 0.023888227737424314, 0.023809251694695235, 0.023802871531580342, 0.023760103167676468, 0.02373575869054119, 0.02365758409404971, 0.023650688225640107, 0.02362295875459742, 0.023597087220171786, 0.023580313163567387, 0.023570486689735243, 0.02353330734732131, 0.023472798060280832, 0.023460215704311317, 0.023454101986041895, 0.02344677134005126, 0.023445686947722394, 0.023440838895586045, 0.02341714796198372, 0.023350715186101798, 0.023338179236143213, 0.023328955980512524, 0.023293298125518825, 0.023249085108923897, 0.023205800809346856, 0.023172120608343783, 0.02310601476439284, 0.023088141719069873, 0.02302845642499871, 0.022981455677822955, 0.022944016283338853, 0.0229080142941586, 0.022895532435806693, 0.022891037939033146, 0.02288984044468359, 0.0228580278113537, 0.02285766963571023, 0.02282176034338691, 0.022729783493948125, 0.022724984446837123, 0.022708557317001093, 0.02267970043754148, 0.022619905209720167, 0.022512852993744153, 0.022459753259869437, 0.02235170520054671, 0.02232944072981465, 0.022327659240668617, 0.022324823723676702, 0.0222432432368242, 0.022234999943010265, 0.022200817136257798, 0.022181424717521298, 0.022159255500333635, 0.022157841284653916, 0.022155716492734314, 0.02212087847478058, 0.022058022745555822, 0.02201744350021152, 0.021997182904511716, 0.0219503584752439, 0.02189522967345422, 0.02188870212875448, 0.021882702075827057, 0.021879737709528523, 0.0218582400946312, 0.0218482080348201, 0.02181140612712812, 0.021791337576480944, 0.021773454290539382, 0.02175391577117172, 0.021745396198249785, 0.021732712037624953, 0.02171852525875806, 0.02171215811418583, 0.021696910110797444, 0.02168907228772531, 0.021661160409518165, 0.021592477121161566, 0.02155465447428957, 0.021420868220308528, 0.021401537792637464, 0.021386509928898324, 0.021384410449479994, 0.021364047910625048, 0.021351921805074822, 0.0213367949417856, 0.021258512262804886, 0.021228004587357237, 0.02122315152711048, 0.021180732368485135, 0.021160474721221616, 0.021151930003586943, 0.021128854924193544, 0.02111931222396375, 0.021110387531159843, 0.021007920288787427, 0.020998569255806662, 0.020997004116827197, 0.02098809135869758, 0.020968589787744223, 0.02096583484895302, 0.0209538575459893, 0.020914838476029124, 0.02090709628136549, 0.02087832387326751, 0.020874057901324704, 0.02086975845774169, 0.02085092555001309, 0.020810218915907085, 0.02079142997394075, 0.02078708683081223, 0.02076345985739685, 0.020745160190346914, 0.020723004266820038, 0.02070483418867381, 0.02069804262913407, 0.02066853924205362, 0.020633895990332767, 0.020606256409844842, 0.020583733052103165, 0.020556489090403425, 0.020539360661856156, 0.02053681882368652, 0.020505279815347815, 0.02046787774823402, 0.020435823571610043, 0.02043460784083002, 0.020423116204508554, 0.020399933520871355, 0.020384705145424974, 0.020377840619624814, 0.020298511045772398, 0.02028322149619495, 0.020272442347558078, 0.020263556492414674, 0.020263093826402068, 0.020259309861340183, 0.02023764142611216, 0.020232262779666645, 0.02021252521027082, 0.02020201942087077, 0.02018466617424302, 0.02018325289725204, 0.020123251714403968, 0.02010266848301003, 0.020088196662497337, 0.020073917683980508, 0.020017832403156546, 0.020008552629007546, 0.019992713588584548, 0.019976968954688964, 0.01991575149743686, 0.019881778554203432, 0.019850137021232228, 0.019844234980422, 0.019748061808761336, 0.019649104292446838, 0.019637968980476938, 0.019587991195240288, 0.019580510396765324, 0.019559231476417773, 0.01955594796343653, 0.019550191772067817, 0.019533802403940665, 0.019526426106018256, 0.019505910010859683, 0.019504691421183475, 0.01947966188619908, 0.019462582168427167, 0.01946244622773929, 0.019449589905057806, 0.019437040464901134, 0.019423176929702704, 0.01941270721390862, 0.01938895480129512, 0.019347473840002412, 0.01931682884415856, 0.019291541876052008, 0.01928051057921227, 0.01927723399353145, 0.019276991072375523, 0.01927643975749698, 0.019273873659335257, 0.019255910869256758, 0.019255206161589985, 0.019226570666838555, 0.01919397302132633, 0.019178177133663467, 0.01907751255772558, 0.01907219565590826, 0.019066771166231396, 0.01906653622827557, 0.019065265443224778, 0.019061153479647135, 0.01905728613566908, 0.019053409162504673, 0.019044441542690176, 0.01902300384153935, 0.019021602139097198, 0.018970214163856053, 0.018966953018414962, 0.018937840305423483, 0.01889148957549546, 0.018876099322776885, 0.018855866704991238, 0.018843530397791183, 0.018811896655682586, 0.018776617227984606, 0.018751942555117928, 0.018739830933670387, 0.018738029573132767, 0.018737030572435316, 0.018717911126575577, 0.018716723568047017, 0.01867562828496258, 0.018672814313796627, 0.018644313284591693, 0.018630292504618704, 0.018606809183001657, 0.018606760373896726, 0.018602649722685147, 0.018581270149971095, 0.018558152162466555, 0.01854169822127419, 0.01853332918002681, 0.018532531867760525, 0.0184924671104149, 0.018484674291086845, 0.018409964591333528, 0.018368729406696236, 0.018354354530726296, 0.018348012880115287, 0.018317687969662502, 0.018312745330105264, 0.01820931506754568, 0.018195780132964797, 0.01819299019543641, 0.018186867075629352, 0.018186474817052687, 0.018138763422166214, 0.018137476116839506, 0.01813694639917475, 0.018103573074400626, 0.018090742944279134, 0.018086091586784245, 0.018070358523375993, 0.018055207217055457, 0.018035412615171872, 0.018004928957901546, 0.01799589078117544, 0.017994041378061442, 0.01798386456460343, 0.017974632470886865, 0.01797073288779465, 0.017965158731105234, 0.01795929818855994, 0.017880367848111704, 0.01787662718690073, 0.01786971976572324, 0.017844082143550544, 0.01780656198782306, 0.017795249352058177, 0.017784672571444966, 0.01774590233985129, 0.017732822898312448, 0.01769143183197905, 0.017667933067762265, 0.017661232049832578, 0.017648340568917852, 0.017636715750387347, 0.017628704329268073, 0.017626674182807243, 0.01760892252712576, 0.017586599012956127, 0.01758638999537005, 0.017584427572910975, 0.017572440101022765, 0.017558158052399225, 0.01752198497775868, 0.01752044593110579, 0.017517396194419173, 0.017516760761595043, 0.017509976866257763, 0.01750489799628677, 0.01746685107723161, 0.017465646645066522, 0.017424008250683264, 0.017420260547666662, 0.017416438307653166, 0.017409007513975783, 0.01738992263727563, 0.017372487648854497, 0.017344519722967973, 0.017303395525982944, 0.01728055028391758, 0.0172713854269159, 0.017262315562443738, 0.017223301702185986, 0.017214061692396213, 0.017207742422479685, 0.017156106280162117, 0.017135301645789865, 0.017116914505461638, 0.017102209014187193, 0.017102135100668124, 0.017033481174145486, 0.017029871908323814, 0.016997130201984886, 0.016989036066616902, 0.01698672771461374, 0.01698042020385789, 0.01697450858830303, 0.016955380795095003, 0.016944778972475948, 0.016897019164968708, 0.016896953887161108, 0.016892770028326592, 0.016871382535632917, 0.016832337786612445, 0.016816753442160742, 0.016798256608344168, 0.016792451800852565, 0.016778889559426222, 0.01676596670709426, 0.016762329471476146, 0.016751349435372424, 0.016740889992965472, 0.016737617903202346, 0.01672414655526021, 0.01670231659290224, 0.016698236674130014, 0.01665205677714879, 0.016651130753898763, 0.01664224546458816, 0.016625028874629508, 0.016579460446289475, 0.016577548913073396, 0.016536274550176627, 0.016529324745830694, 0.016488033081964573, 0.01648719116735267, 0.01647517148027981, 0.01638986097976372, 0.016354970418552148, 0.01635217698843135, 0.016352176903053912, 0.016348440113869357, 0.016315619319265746, 0.01629401442372662, 0.01629000244974599, 0.01628915729696767, 0.016167481858762604, 0.01616390010243186, 0.016162664687452952, 0.01614775976463268, 0.01614120575112431, 0.016092955560763005, 0.016086929261271466, 0.016048125613040004, 0.01603904115560191, 0.016026899470985453, 0.01601779648344733, 0.0160024620032405, 0.016000309618526304, 0.015986663100624427, 0.015965632278913608, 0.015962298660515427, 0.0159451900809466, 0.015935160935521293, 0.01589810852176607, 0.015895394964909493, 0.01589134214504785, 0.01585636114028224, 0.015850392553610444, 0.015843080785002916, 0.015799663107143473, 0.015788765451787715, 0.01578562422096235, 0.01572992095947024, 0.015718510875350762, 0.01570776077241286, 0.015704889658887444, 0.01568560236242996, 0.01568298502160152, 0.015662901335561724, 0.015648123945886692, 0.01564716084467832, 0.015642836290217395, 0.015642436932729906, 0.015609657078618212, 0.015596213228546246, 0.015593975660069972, 0.015593888103939899, 0.015550801186062984, 0.01552223665405419, 0.01546742633706473, 0.01544791965295502, 0.0154476861384071, 0.015442229640888278, 0.015424868622095567, 0.015424670604433605, 0.015416045924705924, 0.015405421857903306, 0.015378212529438159, 0.01532641400944807, 0.015318299082103283, 0.015301873856181845, 0.015290368850845008, 0.01527862862745634, 0.015272855498132175, 0.015246623564593666, 0.015239630456636878, 0.015238923826743921, 0.015222770403055759, 0.015201991104792728, 0.015185942859215354, 0.015180184484740181, 0.01515615433466744, 0.01513040058497593, 0.015119754205290704, 0.015104304449526781, 0.015088421399066344, 0.0150810774660256, 0.015078729552986718, 0.015049420998013688, 0.015048323023200322, 0.015045628987352271, 0.015029524190309613, 0.015026478225219245, 0.014994443733815144, 0.014986091107428207, 0.014978187839273183, 0.014962242069634134, 0.014961014777683825, 0.014910693102011804, 0.01490277207904511, 0.014899549038745548, 0.01489217681637386, 0.014887729739396038, 0.014863976914429039, 0.014862515904907794, 0.014830833386056086, 0.01481681991641948, 0.014813591786458752, 0.014728024055531367, 0.014723041592616285, 0.014722486435105367, 0.014718252599677928, 0.014693013257266963, 0.014645813552422502, 0.014617800537090716, 0.014617240028288864, 0.014605200482527048, 0.014581591659328354, 0.014547375546293418, 0.014537734329987876, 0.01453559339503227, 0.014531965978393326, 0.014518988378845502, 0.014510171340005856, 0.014495307452326136, 0.014443963558874263, 0.014438110109088655, 0.014416663583585976, 0.014411824390197083, 0.014367356892462348, 0.01436485358263707, 0.014363886441732409, 0.01435358671342675, 0.014351710901768247, 0.014338861850128564, 0.01432792931728251, 0.014298516008977708, 0.014288741549327732, 0.014286046164953579, 0.014271393889306296, 0.014231237176866803, 0.01421795648879473, 0.014211842291484963, 0.01417669909677229, 0.014132836379523908, 0.014120732603740284, 0.0141121028828606, 0.014085445218799335, 0.014076465039172195, 0.01404956498336686, 0.014043781056458884, 0.014042033677104934, 0.01399307299331013, 0.013979517968053025, 0.013960683606833224, 0.013922162238515286, 0.013903783841630074, 0.013900893198929114, 0.013886340428831884, 0.01388351835069706, 0.01387997480400602, 0.013860383273357745, 0.013849492163320268, 0.013847317124275392, 0.01376345638670479, 0.013747354207641178, 0.013746161346071255, 0.013719142484099, 0.01369653290755628, 0.013692445330427067, 0.013690831254605662, 0.01365629934617872, 0.013656116832382438, 0.013644950938375498, 0.013644472791450115, 0.013640456797935515, 0.013630319760840077, 0.013608288075114567, 0.013598072264031386, 0.013566016179339589, 0.013559980731249064, 0.013551187390479034, 0.013520144530852624, 0.013519432748948037, 0.013482213210123712, 0.01347518394801483, 0.013465205291997953, 0.013450287497700324, 0.013442595134229716, 0.013438575863236147, 0.013437721746152927, 0.013429483431869203, 0.013419649230283, 0.013396302721388482, 0.013388388817523378, 0.01338793427570813, 0.013373225806838918, 0.013347273207076267, 0.013340537851575032, 0.013323586140189995, 0.013317657332893449, 0.013282557647458473, 0.01328190476374771, 0.013277425170387214, 0.013276656087395715, 0.013271453292170375, 0.013254684124651271, 0.013242648660913238, 0.013211308046851097, 0.013185900718564191, 0.013105268133646854, 0.013099007094083587, 0.013092268882124444, 0.013066840110251823, 0.013062455263145029, 0.013062325713854591, 0.01304824433594794, 0.013035897884475161, 0.013031817069611639, 0.013026769703936568, 0.013021286366946497, 0.013017481908038185, 0.013010708591640743, 0.013006944512737404, 0.01299879699674774, 0.012915403779351582, 0.012912459157780172, 0.012903805916199855, 0.01289701283540929, 0.01289532104265188, 0.012890606487969799, 0.012883410370243263, 0.012878009148465904, 0.012875502862096854, 0.012871848598960307, 0.012832355924799756, 0.012825283693730448, 0.012823612276157654, 0.012787414388536911, 0.012785471787389938, 0.01277198100393075, 0.012731508857952467, 0.012720261170981453, 0.012694551012239404, 0.012666717404837335, 0.012663950218423394, 0.012637625841216667, 0.012599231812294458, 0.012587885073107761, 0.01258575126630783, 0.01256956813756871, 0.01256743137761404, 0.012546127162012905, 0.012541138673288548, 0.012539119919039086, 0.012521982599228789, 0.012519755012564223, 0.012504791755275786, 0.012483804012317325, 0.012482472086149528, 0.012474822681893101, 0.012465156189516676, 0.012456490059373373, 0.01244564231873195, 0.012444787314015356, 0.01243594059818234, 0.012406184581885454, 0.012392544817921389, 0.012371158898723821, 0.01234997475164467, 0.012345464899113406, 0.012334435401214377, 0.012333485933135295, 0.0123329911236042, 0.01233288142359335, 0.012329085207691218, 0.012327590102762694, 0.01230776849608143, 0.012286912865489441, 0.012283247502888804, 0.012269161017761501, 0.012262456225173319, 0.012250413267476213, 0.012239102073588807, 0.01223828399554511, 0.012233462546687694, 0.012230629081993358, 0.012224226805740866, 0.012221506779459114, 0.012220444741388628, 0.012210637762622014, 0.012197641949788993, 0.012190817681758769, 0.012181236559615357, 0.012169207904167423, 0.012168125396505804, 0.012161438218181709, 0.012145341649187477, 0.012137861446602031, 0.012121387332999776, 0.012121022792666195, 0.012109865802295996, 0.012096309493059542, 0.012087720106477212, 0.012081991143632457, 0.012071752472793055, 0.012070730071304913, 0.012058444586388595, 0.012045619419462365, 0.012019437145891638, 0.012016226904638742, 0.012010852732131996, 0.012003869950654968, 0.012003046883119881, 0.012001991867423824, 0.01198467082970815, 0.01197929780803871, 0.011974718914123016, 0.011963772523190542, 0.0119582119743412, 0.011925713661508035, 0.011918975322487356, 0.011914605992940908, 0.011897279091810712, 0.011894349757968537, 0.011880640315861944, 0.011867038487795105, 0.011859658581301481, 0.011839048419294819, 0.011835593434853466, 0.01183256359444593, 0.011810994505888645, 0.01180301124499748, 0.011790085565601294, 0.011782845422614194, 0.01177647108294869, 0.011772203800398576, 0.011764969433389966, 0.011744712049071137, 0.011741306402043322, 0.011736518685703797, 0.011736098556545775, 0.011722130635568907, 0.01171964302655991, 0.011707045248508414, 0.011706493149201552, 0.01168689685339988, 0.011677240589348782, 0.011672732209978318, 0.011654524561763305, 0.011646116556479076, 0.011619122730773366, 0.011582472044487315, 0.011572757828236614, 0.011559706053391197, 0.01154633200172628, 0.011533314084825802, 0.011493629657357443, 0.011491601625708074, 0.011486541385764232, 0.011485963039511677, 0.011475335111784961, 0.011469525882612054, 0.011428210545966284, 0.01141311165958546, 0.011410137174351851, 0.011364280246812429, 0.011342795984564103, 0.01134073105877076, 0.011337568840804967, 0.0113266362883147, 0.01131968844840891, 0.01131358837500818, 0.011306951406426097, 0.011282065035961245, 0.011269261066042193, 0.011268257898905853, 0.011224790999027541, 0.011203288073228528, 0.011199883828074452, 0.011196156124429408, 0.011149665916083141, 0.011147093576078324, 0.011144132722524992, 0.011139657918734221, 0.011115496009184992, 0.011112835546746027, 0.01110866170719365, 0.011047914652755756, 0.011047809161582992, 0.011035041060957481, 0.01103439180974135, 0.011030487815856882, 0.01102979977021895, 0.01102663963307848, 0.011020049917358776, 0.011018333622590368, 0.01099469324139193, 0.010982027866355873, 0.010980272153701834, 0.010964355411266493, 0.01095383643891556, 0.01094933225335772, 0.010935806423216085, 0.010929889287069476, 0.010923107369128679, 0.010910610696312424, 0.010907336675193802, 0.010907304104278611, 0.010904020213225814, 0.010898244238655187, 0.010889831572698508, 0.010885803957500743, 0.010881259711658176, 0.010873022093298455, 0.010866011139432672, 0.01084375391894066, 0.010834558951019688, 0.010823312843862, 0.010822806828049888, 0.0108005304397762, 0.010753966403322367, 0.010753108971575671, 0.01074927095398955, 0.010741142304263736, 0.010736397223584365, 0.010723584552881135, 0.010713917266482048, 0.010698919074274433, 0.010675990575026289, 0.010667645317637734, 0.010657106965243189, 0.01065595963964196, 0.010641148963031432, 0.010629438558948242, 0.010613745324194238, 0.010612006658778601, 0.010604892621877018, 0.010586301077816745, 0.010583247252749846, 0.010579931968068192, 0.010556287356499279, 0.01053442455452, 0.010530540914401771, 0.010529274972832329, 0.010495153357213323, 0.010485760279664563, 0.010472892469530586, 0.010464983979520729, 0.010450910305984773, 0.010446478319101884, 0.010433689752488694, 0.010392878435367748, 0.01039202536894881, 0.010371619712076334, 0.01035330122863865, 0.01033900652190954, 0.010330906349937127, 0.010327024512015746, 0.01031575624722358, 0.010297365341035682, 0.01029736022860629, 0.010289301978539354, 0.010267705490530972, 0.010264313605526126, 0.01025911221711331, 0.010258685026056964, 0.010248738934840107, 0.010221698613247569, 0.010219750600609924, 0.010212340973083442, 0.010207555495817235, 0.010202859167208464, 0.010189935437705007, 0.01018737985623711, 0.010181757288724835, 0.010139032729529625, 0.01013752753686151, 0.010124049995850742, 0.010121962203277894, 0.010112874976357208, 0.010090527233863531, 0.010082727754519866, 0.01008153354410844, 0.010078869368019985, 0.010039106763787017, 0.010021779961457755, 0.010020285239173943, 0.01001920626388968, 0.010013779224086283, 0.010006280967992125, 0.009987436731387281, 0.009962520777881078, 0.00995485223961233, 0.009932909687506732, 0.009927834946079768, 0.009924675967271764, 0.009919671068605591, 0.009898125831651599, 0.009889061087798714, 0.009887954536296092, 0.009884022992952825, 0.009881989632012348, 0.00987503439291142, 0.009865632113230079, 0.009827863169569457, 0.009825417823329078, 0.009796749819453367, 0.009788455470285076, 0.009787835177601614, 0.00978091953071431, 0.009750953210666618, 0.009742932971211813, 0.00974037394962511, 0.009723157891061393, 0.009713135937780783, 0.009699613221329973, 0.009689289587119478, 0.009686356543186558, 0.009676766163278193, 0.009669846184048012, 0.009669781853358652, 0.009656066852881529, 0.009640167581645811, 0.009636633789442055, 0.0096321655301011, 0.009595103272748639, 0.009591306921175406, 0.009583326906684748, 0.00957769183756191, 0.009570119123002275, 0.009556313560005662, 0.009553879371441957, 0.009552186761489419, 0.009545853767475855, 0.00952960992476319, 0.009507627112861617, 0.009499491541521934, 0.009491700674065068, 0.009464094849309917, 0.009452641456805709, 0.009445287301298889, 0.009445111285584923, 0.009436241323654344, 0.009427682388850125, 0.009427052180376327, 0.009419431489243478, 0.009392393140428034, 0.009389152693707463, 0.009388630890595528, 0.009384873159135736, 0.00937236534200564, 0.009358956945609056, 0.009338834194086765, 0.009336586791827193, 0.009335713204492885, 0.009324435262162265, 0.009319304044755422, 0.00930401289583135, 0.009302427747462844, 0.009286331215143287, 0.009267930107247382, 0.009265598949292896, 0.009252771736644023, 0.00921644177471178, 0.009187541586673946, 0.009172596714093706, 0.009164940794197607, 0.009157908774728406, 0.009152990141108736, 0.009150751898303208, 0.009141771299919704, 0.009117972448126014, 0.009099512727690755, 0.00909149223649821, 0.009082194900967261, 0.009081164800593039, 0.009080294115134368, 0.009054011955122974, 0.009046461606011493, 0.009038798517143835, 0.00903215307687189, 0.009027929951422212, 0.009023159255233193, 0.009022890662086018, 0.009021265237174184, 0.00901940073453658, 0.009002590277877483, 0.008988983049203415, 0.00898310664835894, 0.008978988918861558, 0.008974473007172702, 0.008964030905116126, 0.008903534221808024, 0.008893756686461012, 0.008885463010069036, 0.008882334446621405, 0.00887949623514125, 0.008872100560907741, 0.008858840847841604, 0.008856898575741134, 0.008850852198919035, 0.00884847623324194, 0.00878858936408664, 0.008768931274067863, 0.008763257298860811, 0.008759384690801139, 0.008754442637651126, 0.00874844866827939, 0.008732921569913633, 0.008716174145624646, 0.008715201576000038, 0.008711620650959411, 0.008706663282778294, 0.008703964993840903, 0.008699396737799176, 0.0086915065259455, 0.008663069010040433, 0.008661424254636674, 0.008644695462168792, 0.008632068074431794, 0.008621562636863386, 0.008615648551987393, 0.008614939735610769, 0.008587735938214096, 0.008567540699123535, 0.00855823036232355, 0.008555301179804305, 0.008555092810202208, 0.00855253040563398, 0.008550969359897905, 0.008523426332784807, 0.008487773637419056, 0.008476558329948551, 0.008474737288172553, 0.008464594075922855, 0.0084553462892297, 0.008454137356882495, 0.008446719037416756, 0.008423718723057368, 0.00842119770389085, 0.008418508079072483, 0.008413104640909958, 0.008394249189691963, 0.008391968257297882, 0.008387086454718319, 0.008385684684069881, 0.008383416828726578, 0.008379783197555947, 0.008374831389742734, 0.008374248913462215, 0.008355870788393963, 0.008350613636264315, 0.008345093294168122, 0.008336008777668616, 0.008333941568538578, 0.008329435807118993, 0.008322870379677987, 0.00831729789924181, 0.008307436766882031, 0.008303349745621417, 0.008278326474574422, 0.008268939796493789, 0.008262111214512079, 0.008260767607692985, 0.008259482372907126, 0.008255912215948307, 0.008218754016116225, 0.008213345317200946, 0.008206044534613377, 0.008204639011532833, 0.008192469938011876, 0.008177135397019896, 0.008173867350008693, 0.008172723849375054, 0.008166214986365796, 0.008162023134428126, 0.008157835743136445, 0.008144169450014801, 0.0081381522387409, 0.008136652222059079, 0.008134435171869368, 0.008129823715231608, 0.008125278330789363, 0.008124944854125668, 0.008101002801222517, 0.008099140295740126, 0.008096801059509048, 0.008094150614826663, 0.008090328223488636, 0.008068285207636224, 0.008057769878675729, 0.008055639641056895, 0.008051590828086742, 0.008044132781936197, 0.00803082041151459, 0.008023893468039877, 0.008009901023351883, 0.00799189577461268, 0.007989065009824207, 0.007980203129495645, 0.007971223051056738, 0.00796766937254385, 0.007955356281967554, 0.007920442916978932, 0.007913512687317444, 0.007905970726892303, 0.007893929921261844, 0.007893657059433077, 0.007890570025542495, 0.00787767630900895, 0.007865995820655598, 0.007865539545616088, 0.007858710672727389, 0.00783675157962676, 0.007834065480639212, 0.007813909361054366, 0.0078110417591525875, 0.007806029015888014, 0.007801011084422957, 0.0078004441575604926, 0.007797185443866993, 0.007769969548108535, 0.007755933559733781, 0.007745512992603749, 0.007739558222179014, 0.007737164768080996, 0.007730153699377829, 0.0077188954980711745, 0.007715999345594636, 0.007693504219242468, 0.007691402064977543, 0.007688978402419386, 0.0076855240048832995, 0.007672222754528744, 0.007666421969608671, 0.007645010924476087, 0.007636874310447234, 0.007634085618570497, 0.007630897962273588, 0.007630330266789418, 0.007624384781675147, 0.007616537730593698, 0.007611845282046336, 0.0076112824275329305, 0.007610750409508024, 0.00760124424617247, 0.007586943093416319, 0.007586203099142424, 0.00758609946518419, 0.00757184557675357, 0.00756947497640986, 0.007558870689678257, 0.007556869429224093, 0.0075514953910518386, 0.00754556929802209, 0.007541977452237232, 0.007533408560567965, 0.0075102837984260245, 0.007491040751641462, 0.007482650671927157, 0.007475423158456412, 0.007474695564296323, 0.007464382233559283, 0.007437361040963751, 0.007424623705398019, 0.007420654970750248, 0.007418379998085124, 0.007414667032670784, 0.0074111594181070556, 0.007409677562864511, 0.007403028427389853, 0.007401777355706978, 0.007399833485465471, 0.0073875355586543205, 0.007383817253720906, 0.007377030846990597, 0.007345976130878696, 0.007335200318522849, 0.007332481678916258, 0.007318434394917768, 0.007304516319085273, 0.007303574508641062, 0.0073033592499185986, 0.0073021258435590234, 0.007285885162327447, 0.007285554325976094, 0.0072838328778542655, 0.007257184889302824, 0.007242132418853818, 0.007235586244212371, 0.007224139835513502, 0.007218281703214236, 0.0071992692215835105, 0.007191975092337663, 0.007161551543488414, 0.0071577382018149695, 0.007155932769713942, 0.007154875522082753, 0.007142528214818136, 0.007138954594472548, 0.007129195092180601, 0.00712463729500163, 0.007122382618891074, 0.007106118441476992, 0.00710534418004807, 0.007104964020600304, 0.007089555303048068, 0.007066420953469945, 0.007044533627634591, 0.007042005168130196, 0.007037797277915038, 0.007031148912111607, 0.007025211905500319, 0.00702361994380574, 0.007022534158099294, 0.007020668244204097, 0.007020222435086988, 0.007019966638324634, 0.007018987613437385, 0.007013235266163911, 0.006982253841733011, 0.006980084195983004, 0.006977185988685413, 0.006958045637666771, 0.006954080270461498, 0.006952994782389075, 0.006943820209066095, 0.006943817585062206, 0.006943031061210565, 0.00693660817960499, 0.00693058392500567, 0.006920033835705082, 0.006916055811377586, 0.0069122964566467595, 0.006888162428157029, 0.00686968677644531, 0.006860592187661884, 0.006856167566976596, 0.006818610852928323, 0.006815588074365432, 0.006809034878942649, 0.006807495548395112, 0.006804417838899447, 0.006793325980098755, 0.006790465719381388, 0.006762644786500612, 0.006753639081795328, 0.0067455019656899136, 0.006744117348077529, 0.006738406885715938, 0.006734547451455489, 0.006722950905796285, 0.006719629726339139, 0.006719067994262667, 0.006714778586458971, 0.00671381522694866, 0.006710170943510245, 0.006708627485034995, 0.006704940063941206, 0.006701109081559833, 0.006693280923950289, 0.006667591810407068, 0.006667439574294643, 0.006667295433836731, 0.006656198066975204, 0.00663426412452598, 0.0066282956101481145, 0.0066072677426427745, 0.006588664741787475, 0.006571145086281226, 0.006570252660973826, 0.006561319156131239, 0.006559094478520403, 0.006555750662841383, 0.006549336031756566, 0.006548757680157671, 0.006537156548028629, 0.006534739027039951, 0.006519458743246751, 0.006517661456110392, 0.006514335605904511, 0.006466020974132827, 0.006452457085802964, 0.006449340502422691, 0.0064470476086018, 0.006444923886276676, 0.006444421294035771, 0.006435347547473782, 0.006416710863623757, 0.006397335796077044, 0.006377991011672819, 0.0063653622704251235, 0.006361290072228288, 0.00636001248205122, 0.006359230549906081, 0.006354916051021035, 0.006347532899639366, 0.006340990644346211, 0.006338267060590609, 0.0063326089909739305, 0.006329905123550328, 0.006312465504641981, 0.0063041100621875, 0.006283852825365194, 0.0062754486310074, 0.006268342312692793, 0.0062482672560667625, 0.006246858940766998, 0.006241868823579857, 0.006238274648161749, 0.006236017700085174, 0.0062220252562575195, 0.006214236170877174, 0.006207258556556753, 0.006197558150291954, 0.006196400960220225, 0.006193539866207286, 0.00618721690503533, 0.006185655835284083, 0.0061777562483353145, 0.006151342040003888, 0.006142345311540651, 0.006124042918591585, 0.006121147885103246, 0.006107729387304122, 0.006102720327281924, 0.006084478851951578, 0.006081288152958256, 0.0060664608824001825, 0.006062772069504695, 0.006048962432489644, 0.006046279592368913, 0.006035714767235463, 0.006032150349220403, 0.006027856637146577, 0.0060178015160950345, 0.006015769475806531, 0.00600776812002235, 0.006002076173685699, 0.006000149314592672, 0.005994127980052321, 0.005985294882401985, 0.005974972673186748, 0.005970670162189267, 0.005965511619497495, 0.005955294740625971, 0.005954549938710009, 0.005950706527334829, 0.005946452755022778, 0.005939722128059873, 0.00593675859192402, 0.005936349222036716, 0.005911364762035845, 0.005893890544041349, 0.0058890546778067945, 0.005872953535170186, 0.005850824561877286, 0.0058421863921227805, 0.00582505860814178, 0.005816933502597662, 0.005816715586496487, 0.0058146938971148695, 0.005801065124196197, 0.00579578483693588, 0.005794971124459364, 0.0057942745313716, 0.005789189233347659, 0.005779531165955639, 0.00577716490051331, 0.005770723189393796, 0.00576452394544149, 0.005749861616692208, 0.005736416583491633, 0.005734616449492622, 0.005731151606626494, 0.0057270932805475695, 0.005722983278461113, 0.005716577212551534, 0.005711569519011758, 0.005705200204336208, 0.005691405634200843, 0.005688538751358492, 0.005673886427908426, 0.005671070028761701, 0.005651540486352138, 0.005648493187646684, 0.00561579881016792, 0.005604861903784547, 0.0055766402992929835, 0.005573761890277873, 0.005563883560298797, 0.005562051685987083, 0.005558016941641456, 0.005552809017807548, 0.005537649471576133, 0.005530358364180359, 0.005530107444524294, 0.005508225032779213, 0.005505478272303106, 0.005490170610571446, 0.005488679703241034, 0.005488672500744581, 0.005475122992208524, 0.005462985220937687, 0.00545876344207289, 0.005452075898880538, 0.005442850043341678, 0.005441012138184891, 0.0054291370576055025, 0.00542739506625548, 0.005426163972529383, 0.005418655306180371, 0.005399831783105902, 0.005389330560175272, 0.00538755171953142, 0.0053841577249802205, 0.005372752003982144, 0.005362067515174712, 0.005333520694169019, 0.0053241574021137775, 0.005318584697030456, 0.005297649423509335, 0.005293419948817619, 0.005292598398198293, 0.005290782723526332, 0.005282268885964643, 0.005280374739401175, 0.005272918888685817, 0.0052679345346847775, 0.005266446978695473, 0.005265754452572764, 0.005263694517489138, 0.005261846639305301, 0.005255363646766696, 0.005233497533690116, 0.005216703960343034, 0.005215298854517516, 0.00521136418509945, 0.005203717147300956, 0.0052002419188190655, 0.005198305265681659, 0.005190618941983324, 0.005185866973425097, 0.005183733065924701, 0.005182956440139593, 0.005182195978022776, 0.005178473654183845, 0.005177505883548975, 0.0051687911974252375, 0.005168454354378571, 0.005161710921347466, 0.005157230773862865, 0.005153978247434024, 0.005153299266209705, 0.005137400906932549, 0.0051312874016503605, 0.005128212441221803, 0.0051104208968169, 0.005105183553790618, 0.0051013342051680465, 0.005096778660121538, 0.005092257605763881, 0.005063295057737533, 0.005046716163051841, 0.00504233385629496, 0.00503885570322231, 0.0050299145563463725, 0.005007461752941659, 0.005004846361448172, 0.005004104487635931, 0.005003249014776904, 0.004979768173417583, 0.0049767905539476135, 0.0049696382335354655, 0.004963369119162307, 0.004961209022738359, 0.004960927686836842, 0.0049605000759121234, 0.0049566026002005725, 0.0049508703099613955, 0.004946937500982701, 0.004937877879426548, 0.004934550030513179, 0.004932529752694528, 0.004924022115771845, 0.004919755217103876, 0.0048908692670684905, 0.004882376219969394, 0.004870558504012369, 0.004866951780142802, 0.004866632787346519, 0.004862549996699085, 0.004861352818905106, 0.004855007548032966, 0.004831511915537553, 0.004828999707666732, 0.004816819563027688, 0.004815709631929056, 0.004811209365737946, 0.004755812026409037, 0.004744205843886769, 0.004739047840659776, 0.004732145343597624, 0.004724327311176138, 0.004724153452860264, 0.004719788883123939, 0.004710568551990649, 0.004709098698155431, 0.0047071146764080495, 0.0046989722003635105, 0.004695787518009569, 0.004691433829231379, 0.004690566433364828, 0.004687407356764638, 0.00468672148866595, 0.0046803596517242824, 0.004676812950665549, 0.004673094568317228, 0.00464123279249223, 0.004636129996060216, 0.004631624512974513, 0.00463116916032758, 0.004624187164673697, 0.004621471734903265, 0.0046160568212510284, 0.004607196910686154, 0.004571633882652063, 0.004570518268658114, 0.004569123814848979, 0.0045684847312660185, 0.004565929697231992, 0.00454942138612968, 0.004542311194599982, 0.004532303230503205, 0.004528941425841954, 0.004507475476942271, 0.004500347451504793, 0.004485201255407835, 0.0044763104800218225, 0.0044683753622031044, 0.004464858270260724, 0.004449458251835663, 0.0044381760494897156, 0.004414323169663217, 0.004413345694198814, 0.004411006201054712, 0.004403407015257509, 0.004397191477580945, 0.0043868230384838105, 0.004378373436335653, 0.0043588971252059685, 0.004354704189675961, 0.004330135331214092, 0.004329858957012132, 0.0043126051011665185, 0.004308805874056044, 0.004308582353512008, 0.004303477766489841, 0.0043030765063422575, 0.004291467231444857, 0.004283400469709146, 0.004273317453582917, 0.004266774342184777, 0.004265514535510032, 0.004265395676794724, 0.004257264196105983, 0.004256017103127868, 0.0042297369166832775, 0.004225635165544221, 0.004223512657743281, 0.004221133074297756, 0.0042171114624032745, 0.004210637691113856, 0.004175399168474228, 0.0041595117547564885, 0.004139598671019766, 0.004137857484747902, 0.004118776532995931, 0.004112801414045789, 0.004099580267443088, 0.004095737241239572, 0.004091485316532905, 0.004086693390150265, 0.004075830476534963, 0.004074816750605295, 0.004073077303581208, 0.004070163671838625, 0.004069570908042196, 0.00406922261274615, 0.004056569172502732, 0.004054857382446812, 0.004050284973081963, 0.004029913631910059, 0.004025658235471316, 0.00402183610985146, 0.00400576655975571, 0.003997276150653801, 0.003984234063943274, 0.00397681834780879, 0.0039658653922418526, 0.003961176464355048, 0.0039506375336662075, 0.003943524391925026, 0.003943362034897826, 0.003923540043089742, 0.003915281296543051, 0.003912573035733225, 0.0038857674247291143, 0.003878124769315443, 0.00387269232331102, 0.003872441863638441, 0.003859447704465105, 0.00385226732312711, 0.00384783015387071, 0.0038437114414516076, 0.00384301615604888, 0.0038372520482718823, 0.0038222010001313354, 0.0038116455779831516, 0.0038023366344219407, 0.003801315602406631, 0.0037968331754993823, 0.0037890892791560067, 0.0037825907662336505, 0.0037720007921222703, 0.0037708264386325146, 0.003765591793052176, 0.003758783391936154, 0.003747115755360825, 0.0037404344248806193, 0.0037363176553203248, 0.003735480246076979, 0.003681312860359514, 0.0036807141975318497, 0.0036589370186626367, 0.003652830709627842, 0.003647825926155273, 0.003646597537426537, 0.0036391569799663734, 0.00363589415348287, 0.0036343125834668293, 0.0036339756838103775, 0.003621413029997861, 0.003615490342174202, 0.0036142243922724867, 0.003592544247172808, 0.003589168667911704, 0.003586951359399327, 0.0035846141073883, 0.0035832816985655485, 0.003570165287083708, 0.003569848819380799, 0.003568099216711097, 0.0035676309887613146, 0.0035619630521426383, 0.0035569941550895696, 0.003553214898712846, 0.0035513187024929006, 0.00355078353413608, 0.0035485828302175945, 0.003526124653879922, 0.003515209725349681, 0.0034867626904577544, 0.003462549469771245, 0.003453905314939073, 0.003453296110571399, 0.0034531324901443386, 0.003436265680042898, 0.00343426838815985, 0.0034330171149391272, 0.0034303417735482293, 0.0034299883731892878, 0.003427656405813109, 0.003426804821398969, 0.0034235063566375795, 0.0034203185011572853, 0.0034166709697985484, 0.003405547845526762, 0.003400007955082666, 0.003381977291645946, 0.003380150142867679, 0.003369463553201454, 0.0033675756585747844, 0.0033552679056117305, 0.003346611462124843, 0.0033423241217259807, 0.0033421423518798224, 0.0033419359471338456, 0.0033417963358130503, 0.0033373654344959394, 0.0033336597035981247, 0.0033271319705959323, 0.003317051759651309, 0.003309585500931966, 0.003301291734716313, 0.0032988589056289603, 0.0032973519700037353, 0.0032861151039141135, 0.0032848452982550272, 0.0032788402843791273, 0.003277919408354096, 0.0032750230633152608, 0.003274544433650944, 0.0032588136253054205, 0.0032562703002910497, 0.003244272829342836, 0.00324207268562024, 0.0032346435803859586, 0.0032313668909737477, 0.003229099843465705, 0.003222993382223655, 0.003222966187145427, 0.003220667494667701, 0.003218111396739474, 0.0032170209641779715, 0.003207294412918498, 0.0032004731664885618, 0.0032000776105036498, 0.0031965461048450174, 0.003194228025323464, 0.0031942209199584894, 0.00318738714969621, 0.0031603945788989275, 0.0031594557467356675, 0.0031592772175422367, 0.003146028311338926, 0.0031451477968171366, 0.003144977396184629, 0.0031437989368143836, 0.0031429346725414505, 0.0031412758096071645, 0.003129315787069984, 0.0031213167477711855, 0.0031125535202951703, 0.0030975947786756304, 0.0030950756992253257, 0.003090984292270201, 0.003090235418814603, 0.0030850734564990515, 0.003080708084282355, 0.003074422858822885, 0.003073162260483815, 0.003064585331146574, 0.00305331714845758, 0.0030507930342490064, 0.0030501757080794467, 0.003036570023754687, 0.0030354029881223834, 0.0030265487824153556, 0.0030123677659656505, 0.003006765681965463, 0.0030060895584385367, 0.0029996770261467675, 0.0029948416784579173, 0.0029924076254360743, 0.002992000139328876, 0.002961191334571906, 0.002960125591116123, 0.002948817744432326, 0.0029485983433387955, 0.0029458581569102114, 0.0029401267277309037, 0.0029283626445763154, 0.0029282990658375165, 0.002927407976445335, 0.0029172237871715376, 0.002911352003191421, 0.0029072179354391924, 0.0028859721726686182, 0.002883784317086258, 0.002882552888418638, 0.0028798781744745062, 0.0028736426737502796, 0.0028732520973869208, 0.0028656308167912276, 0.00286506009785814, 0.002856285824302953, 0.002853596024596205, 0.0028472824604505605, 0.0028433300745714643, 0.0028376883816449033, 0.002835797913357708, 0.00282148019610102, 0.002817555492724244, 0.002814377469152175, 0.0028107137716944447, 0.002809002534927058, 0.002801554864675074, 0.0027963111045527294, 0.002795827870341699, 0.002790243579760156, 0.0027885290097290844, 0.002774736023279084, 0.002768920907046452, 0.002764320033147624, 0.002761816175733984, 0.0027511825713874, 0.0027461128690389595, 0.0027422723020020267, 0.002742156431911897, 0.0027392427225650644, 0.002738790703061185, 0.002737766728982399, 0.0027316006690996475, 0.0027263226116664304, 0.0027017191495600475, 0.002700962098642, 0.002698971167723301, 0.002698290074765532, 0.0026953226305339974, 0.002692353318404504, 0.002691830434437348, 0.0026916752297486226, 0.0026899320609219475, 0.002676301229839589, 0.00265227102027696, 0.0026505882459871843, 0.0026497721632770827, 0.0026495998215592177, 0.0026463104187451373, 0.002645549402195347, 0.0026320508158537885, 0.002631752869971411, 0.002629323826747266, 0.0026281956653065658, 0.002597510251859784, 0.0025955924433840893, 0.0025898794742237647, 0.0025866060347893285, 0.002585599129064938, 0.0025784336499786297, 0.0025747457107905794, 0.002556345575682118, 0.002538073141839754, 0.002527102509186718, 0.0025269777741477924, 0.002520927411465247, 0.0025193825219374266, 0.0024994679266279332, 0.0024934028711792347, 0.0024815691369225582, 0.002477214817683696, 0.0024704451173633724, 0.002468769687484472, 0.002466150819949065, 0.0024652974245543417, 0.0024646096866614117, 0.0024567311981379273, 0.002438283164308132, 0.0024335067446051516, 0.0024275417537825443, 0.0024243546192991533, 0.0024237253460432993, 0.002417861376552512, 0.0024123860169851614, 0.0024100382686239206, 0.0024079851247292275, 0.0024067719198573884, 0.002395704242877566, 0.0023830864014717803, 0.0023814897274822343, 0.002381068789513944, 0.002379280973014308, 0.0023742988203774946, 0.002373546430993534, 0.0023698948622291847, 0.002367339734219047, 0.002355694764665873, 0.0023517962588016487, 0.002348777776253127, 0.0023294147121144617, 0.00232528825486962, 0.0023145159040340677, 0.002293776323596856, 0.002292255326452488, 0.002289494103762717, 0.0022893635552669782, 0.0022779303583027963, 0.002272434085612843, 0.0022717361172362067, 0.0022624612712374872, 0.0022490478221318683, 0.00224590551908723, 0.002245396890116422, 0.00223755498256569, 0.0022310164981006048, 0.0022290665465969114, 0.0022232698782664964, 0.002220427252002519, 0.0022036225619144222, 0.002202359886021387, 0.0021999930816464994, 0.0021945098708254095, 0.002187813526506519, 0.002187609982448712, 0.0021845412748647906, 0.0021743995312406405, 0.002173960532180746, 0.0021717891641887086, 0.0021685933621799335, 0.0021643719976512242, 0.002152902398531668, 0.002148993324820859, 0.0021469331581239776, 0.0021278864014070116, 0.0021250483141891066, 0.00211519999370502, 0.0021140758211102557, 0.0021138913050701507, 0.0021016432171424727, 0.0020917846791246057, 0.0020888114363382224, 0.002085168711182502, 0.002082184474957203, 0.002067619569787347, 0.002067376493651427, 0.002062863079895223, 0.002062291838657339, 0.0020609005823207837, 0.002060305740496606, 0.002031244385615722, 0.002022276614111663, 0.0020154025880907596, 0.0020151299721044933, 0.00198575867128284, 0.0019781977679034315, 0.0019724496310763264, 0.001970235375623375, 0.001962648634478535, 0.001962572115740823, 0.0019502181695154493, 0.001950112296398028, 0.0019466884748451678, 0.0019449993942204093, 0.0019430532783467286, 0.001937500656394708, 0.001917924504604481, 0.0019093162879065284, 0.0019039670572630792, 0.0019022484670884634, 0.0019005607597235466, 0.0018968513793959942, 0.0018818357233429369, 0.001878211152086492, 0.0018764887596035475, 0.0018745249193598715, 0.001865507535726208, 0.0018623975625787204, 0.0018368739180957604, 0.001836188597275411, 0.0018290922681247043, 0.0018285979606430232, 0.0018227168038258345, 0.0018204146913624597, 0.001793444721522382, 0.0017852837937226511, 0.0017705066945066543, 0.0017685176114059793, 0.001766295440349762, 0.0017649814898094067, 0.0017561098942379667, 0.0017448161522705793, 0.0017425286476177794, 0.001736445554652166, 0.0017346785708408725, 0.0017311167944218373, 0.0017240969107905851, 0.0017239585019576422, 0.0017141135592443225, 0.001714112375599479, 0.0017074450417522062, 0.0017036727773873358, 0.0016991487815225385, 0.0016748324977483389, 0.0016714795962261715, 0.0016697698365786525, 0.0016667303463978145, 0.0016650305169695352, 0.0016464015034158633, 0.0016461953018000043, 0.0016352985926621144, 0.0016310698187820783, 0.0016285734343848119, 0.0016277263728332277, 0.001625570669686658, 0.0016199550620339467, 0.001616940778278055, 0.0016126203159842934, 0.0016092660581011617, 0.00160815233076263, 0.001604956250648246, 0.0016035203628812162, 0.0015973432870293595, 0.0015839824766228786, 0.0015816270550948752, 0.0015565126352646247, 0.0015533079588124763, 0.0015489287168933981, 0.001547529663316954, 0.001543512151797899, 0.0015431615232376098, 0.0015356699345785083, 0.0015315183566662208, 0.0015140841504210092, 0.001510772099941978, 0.0015074504067744533, 0.0015035569705954023, 0.001494626395505069, 0.0014874484126719033, 0.001486081213068535, 0.0014795970201745838, 0.0014761325456428523, 0.0014617686616253817, 0.0014517400230697752, 0.001451183610752953, 0.0014457339532878088, 0.0014255719535077199, 0.0014209445097928053, 0.001412491770384516, 0.0013992980198325772, 0.0013852459868955512, 0.0013721118735645851, 0.0013705372272789197, 0.0013644401850117893, 0.0013620021365789718, 0.0013583384489664462, 0.001350996535072591, 0.0013493231539743224, 0.0013469771491706824, 0.001337854702555208, 0.0013330957020738837, 0.001329476835024773, 0.0013252021124751118, 0.001310682103265113, 0.001289384487358564, 0.0012813143273099474, 0.001280320582972796, 0.0012786100036957138, 0.001276850457048717, 0.001275487029358398, 0.0012703398244523914, 0.0012598362592552439, 0.0012597994194796405, 0.001256942265243982, 0.0012534399504366294, 0.0012394474237263687, 0.0012281120251339639, 0.0012232490529620493, 0.0012168165356912534, 0.0012157506842999074, 0.0012146493625448064, 0.0012132369876718444, 0.0012093065805198217, 0.0011960648142369888, 0.00119157964931556, 0.0011766840403607125, 0.0011705473438595325, 0.0011700079554662125, 0.00116696128935088, 0.0011623206379287642, 0.0011464596209970817, 0.0011454485511811585, 0.0011137145400768808, 0.0011003260806777704, 0.0010942375292328065, 0.0010894773864624108, 0.0010848984914701891, 0.0010752194857239778, 0.0010644528231364809, 0.0010615109236266143, 0.0010571187485666717, 0.0010562794815204264, 0.0010530904991797074, 0.0010530634529620406, 0.0010492000762487561, 0.0010416444565129412, 0.0010357632310573266, 0.0010350150243922246, 0.0010341859593902439, 0.0010312674366952897, 0.0010296617185978725, 0.0010252564692252377, 0.0010186502904078968, 0.0010141874085072774, 0.0010077304042035735, 0.0010008157995563616, 0.000993761763382641, 0.0009871481657149038, 0.0009819701500686849, 0.0009817311075841029, 0.0009812251298829619, 0.000966988053733135, 0.000949757604162438, 0.0009477257467679659, 0.0009397566137665098, 0.0009392773229334935, 0.0009368269345576115, 0.0009272774298854029, 0.0009170161078768029, 0.0009119495189875387, 0.0009070312150440945, 0.0009047342554001703, 0.0008946648038246601, 0.0008906195578269072, 0.0008852407982938486, 0.0008837095656903313, 0.0008742034728032638, 0.0008729596558533028, 0.0008676581692875032, 0.0008528603716597729, 0.000844270710967686, 0.0008376004701471968, 0.0008187533506138479, 0.0008174927820577977, 0.0008070337638684648, 0.0007874938464622905, 0.0007834274380437055, 0.0007754084484546534, 0.0007738744648553733, 0.0007706251676856629, 0.0007634518760219677, 0.000761549466674857, 0.0007584915191310121, 0.0007523399326714493, 0.0007517844631432566, 0.0007468890842386034, 0.000744580002652926, 0.0007425674082685887, 0.0007398329413732558, 0.0007380817675832166, 0.0007364015666208453, 0.0007339098876389669, 0.0007319097510741098, 0.0007304615757636338, 0.0007288479946985333, 0.0007261811700113614, 0.0007254558943157332, 0.0007214294128254751, 0.0007156356244035063, 0.0007052636888021939, 0.0006968351093385827, 0.0006947721585189566, 0.0006926479056033121, 0.0006884269670037699, 0.0006881553764319019, 0.0006860672300649961, 0.0006850504276149296, 0.0006811210909994159, 0.0006799401816987387, 0.0006689050360520643, 0.0006688066781143785, 0.0006621761480109811, 0.0006534283767126749, 0.0006470925511128741, 0.0006449111084289742, 0.0006343828643919577, 0.0006321847918483816, 0.000629006546905874, 0.0006219142655154511, 0.0006174846913876047, 0.0006174040294498729, 0.0006023604188636206, 0.0005941233626395353, 0.000584827597517212, 0.0005793008072477977, 0.0005737144800970046, 0.0005709053965537908, 0.0005604735584733245, 0.0005560666190663311, 0.0005549167556910938, 0.0005537311275338938, 0.0005509877084945543, 0.0005509639646142067, 0.0005500236531622914, 0.0005449551175611036, 0.0005434430399908733, 0.0005423714436984079, 0.0005411078721175764, 0.0005368831800476858, 0.000533713587739406, 0.0005332744954172505, 0.0005249597496964202, 0.000520126505496002, 0.0005110376512079869, 0.000510593737355707, 0.0004953945814212956, 0.0004843795354778221, 0.0004763490779652086, 0.0004727819452940486, 0.0004707721682509297, 0.0004677390376908849, 0.0004517233469803214, 0.000450589132542111, 0.0004425863613690173, 0.00043543706553072397, 0.00043413668018298416, 0.00043196362508412535, 0.00042586319474845885, 0.0004219110561416951, 0.0004171553190069233, 0.00041067273225292735, 0.00040536261482797693, 0.00040273936784529946, 0.0003806141897538239, 0.0003803923762050924, 0.00037680355170991743, 0.00037566284044449603, 0.00037163440674609647, 0.00036887051207902576, 0.0003599314785291479, 0.0003507024101741779, 0.00034730445629961105, 0.000338106272543397, 0.00033472081419319745, 0.00032952585619233323, 0.000328405928508828, 0.0003047970028463467, 0.0003007781204342645, 0.00029810587166588634, 0.0002899500260772053, 0.00027347758678812357, 0.0002665504204953379, 0.00026407567566568574, 0.0002478607042465633, 0.00024394174575095932, 0.00024335628301864188, 0.00023955260835982568, 0.00023851863461714476, 0.0002333507489221002, 0.0002301357085525763, 0.00022392080700983988, 0.00022017512096367758, 0.00021625242918080564, 0.00021581738879035338, 0.00020591282543350338, 0.00020450673734109624, 0.0002015013241901178, 0.00018449237807229284, 0.00018078352087172813, 0.00017662475595471065, 0.0001760445927074404, 0.00017528901097279713, 0.00016342182815325883, 0.00015808985074915104, 0.00014808423188847998, 0.0001396063345345991, 0.00013635613999913375, 0.00013482074540858565, 0.0001308245401912572, 0.0001122043270424493, 0.0001046037398537401, 0.00010298072305922402, 0.00010129236709636918, 0.00010061881060185047, 8.526044646956591e-05, 8.405540480549963e-05, 8.077685264756608e-05, 7.559306673160846e-05, 7.183655145724924e-05, 7.165325780449092e-05, 6.390536993181309e-05, 6.044530191802389e-05, 5.450130201436927e-05, 4.554466484614776e-05, 4.345080416869645e-05, 4.2937453810506954e-05, 4.1008748820287046e-05, 3.520053098248049e-05, 2.205452171405253e-05, 1.943329368652568e-05, 1.568373320865554e-05, 1.3221773433397108e-05, 3.717859150331898e-06, 2.8928183894450143e-06, 1.598425951932602e-06, 6.502040630974024e-07]\n"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in range(len(X_test)):\n",
    "    X_out = new_model(X_test[i].float())\n",
    "    # print(X_out)\n",
    "    Y_out= y_test[i]\n",
    "    # print(Y_out)\n",
    "    array.append((sum((X_out - Y_out)**2)).item())\n",
    "    # array.append(loss_fn(X_out, Y_out).item())\n",
    "print(sorted(array)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.sort()\n",
    "array[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008284977062343048"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, f'./model_freezes/{datestring}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240512-202435'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
