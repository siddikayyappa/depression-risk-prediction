{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from fasttext import FastText\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = FastText.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    def __init__(self, model) -> None:\n",
    "        self.model = model\n",
    "    def get_embeddings(self, words):\n",
    "        return np.array([self.model.get_word_vector(i) for i in words])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pkl.load(open('./tags.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_class = Embeddings(model)\n",
    "ems = embedding_class.get_embeddings(tags[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "anew_dataset = pd.read_csv('./warriner_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "anew_dict= dict()\n",
    "words = anew_dataset['term']\n",
    "valence_ratings = anew_dataset['pleasure']\n",
    "arousal_ratings = anew_dataset['arousal']\n",
    "word_embeddings = embedding_class.get_embeddings(words)\n",
    "word_embedding_dict = dict(zip(words, word_embeddings))\n",
    "for i in range(len(words)):\n",
    "    anew_dict[words[i]] = [valence_ratings[i], arousal_ratings[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = word_embeddings\n",
    "Y = np.array([anew_dict[i] for i in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.26, 2.41],\n",
       "       [5.3 , 2.65],\n",
       "       [2.84, 3.73],\n",
       "       ...,\n",
       "       [7.  , 5.63],\n",
       "       [5.86, 5.68],\n",
       "       [6.3 , 4.18]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03986298,  0.00379052, -0.0127756 , ..., -0.01078152,\n",
       "        -0.02300994,  0.0079215 ],\n",
       "       [ 0.02610103,  0.01788571,  0.00896458, ...,  0.0547346 ,\n",
       "         0.02627475,  0.02617722],\n",
       "       [-0.01662364, -0.06317363,  0.10360997, ..., -0.00658366,\n",
       "        -0.00859841, -0.0122865 ],\n",
       "       ...,\n",
       "       [ 0.01154633,  0.02386309,  0.02965424, ...,  0.02644203,\n",
       "         0.09439246,  0.01073311],\n",
       "       [ 0.01526884, -0.06252627,  0.06748683, ..., -0.06219679,\n",
       "        -0.09277178, -0.06651503],\n",
       "       [ 0.04610313,  0.01816115,  0.03932561, ..., -0.00771078,\n",
       "        -0.03635433,  0.0058565 ]], dtype=float32)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = Y/10\n",
    "# SCaling the data -- large loss issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.626, 0.241],\n",
       "       [0.53 , 0.265],\n",
       "       [0.284, 0.373],\n",
       "       ...,\n",
       "       [0.7  , 0.563],\n",
       "       [0.586, 0.568],\n",
       "       [0.63 , 0.418]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03986298,  0.00379052, -0.0127756 , ..., -0.01078152,\n",
       "        -0.02300994,  0.0079215 ],\n",
       "       [ 0.02610103,  0.01788571,  0.00896458, ...,  0.0547346 ,\n",
       "         0.02627475,  0.02617722],\n",
       "       [-0.01662364, -0.06317363,  0.10360997, ..., -0.00658366,\n",
       "        -0.00859841, -0.0122865 ],\n",
       "       ...,\n",
       "       [ 0.01154633,  0.02386309,  0.02965424, ...,  0.02644203,\n",
       "         0.09439246,  0.01073311],\n",
       "       [ 0.01526884, -0.06252627,  0.06748683, ..., -0.06219679,\n",
       "        -0.09277178, -0.06651503],\n",
       "       [ 0.04610313,  0.01816115,  0.03932561, ..., -0.00771078,\n",
       "        -0.03635433,  0.0058565 ]], dtype=float32)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(X, open('X.pkl', 'wb'))\n",
    "pkl.dump(Y, open('Y.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(300, 150)\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 100),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 10),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.output = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.linear_stack(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 0.03965025395154953, Test Loss: 0.016283055767416954\n",
      "Epoch 1, Training Loss: 0.020473076030611992, Test Loss: 0.018051644787192345\n",
      "Epoch 2, Training Loss: 0.014948079362511635, Test Loss: 0.012875258922576904\n",
      "Epoch 3, Training Loss: 0.020394958555698395, Test Loss: 0.01282814983278513\n",
      "Epoch 4, Training Loss: 0.012756689451634884, Test Loss: 0.014629033394157887\n",
      "Epoch 5, Training Loss: 0.01207746472209692, Test Loss: 0.011902880854904652\n",
      "Epoch 6, Training Loss: 0.010303876362740993, Test Loss: 0.007322913967072964\n",
      "Epoch 7, Training Loss: 0.009552392177283764, Test Loss: 0.008895674720406532\n",
      "Epoch 8, Training Loss: 0.004179859533905983, Test Loss: 0.010986573062837124\n",
      "Epoch 9, Training Loss: 0.008886546827852726, Test Loss: 0.011616934090852737\n",
      "Epoch 10, Training Loss: 0.005075789522379637, Test Loss: 0.005623146891593933\n",
      "Epoch 11, Training Loss: 0.01110783126205206, Test Loss: 0.00900776032358408\n",
      "Epoch 12, Training Loss: 0.004896960686892271, Test Loss: 0.008289809338748455\n",
      "Epoch 13, Training Loss: 0.007939931005239487, Test Loss: 0.00534795643761754\n",
      "Epoch 14, Training Loss: 0.007322628516703844, Test Loss: 0.0063182879239320755\n",
      "Epoch 15, Training Loss: 0.009277701377868652, Test Loss: 0.010840668343007565\n",
      "Epoch 16, Training Loss: 0.0020056627690792084, Test Loss: 0.007624233607202768\n",
      "Epoch 17, Training Loss: 0.00954362377524376, Test Loss: 0.010696099139750004\n",
      "Epoch 18, Training Loss: 0.005617586895823479, Test Loss: 0.005051286891102791\n",
      "Epoch 19, Training Loss: 0.0043993182480335236, Test Loss: 0.0038315316196531057\n",
      "Epoch 20, Training Loss: 0.006361639127135277, Test Loss: 0.007595452480018139\n",
      "Epoch 21, Training Loss: 0.011223378591239452, Test Loss: 0.006142052356153727\n",
      "Epoch 22, Training Loss: 0.00472267298027873, Test Loss: 0.0069506424479186535\n",
      "Epoch 23, Training Loss: 0.004942500032484531, Test Loss: 0.008141822181642056\n",
      "Epoch 24, Training Loss: 0.0035475664772093296, Test Loss: 0.011959017254412174\n",
      "Epoch 25, Training Loss: 0.004588654264807701, Test Loss: 0.00949185062199831\n",
      "Epoch 26, Training Loss: 0.004134186543524265, Test Loss: 0.00859020370990038\n",
      "Epoch 27, Training Loss: 0.005723300389945507, Test Loss: 0.0074430122040212154\n",
      "Epoch 28, Training Loss: 0.005468813702464104, Test Loss: 0.00758328614756465\n",
      "Epoch 29, Training Loss: 0.004559854045510292, Test Loss: 0.006978027988225222\n",
      "Epoch 30, Training Loss: 0.008524050004780293, Test Loss: 0.0036782941315323114\n",
      "Epoch 31, Training Loss: 0.005131568294018507, Test Loss: 0.004736374132335186\n",
      "Epoch 32, Training Loss: 0.002647536341100931, Test Loss: 0.00751896295696497\n",
      "Epoch 33, Training Loss: 0.004995794966816902, Test Loss: 0.007451507728546858\n",
      "Epoch 34, Training Loss: 0.004168317187577486, Test Loss: 0.006552479695528746\n",
      "Epoch 35, Training Loss: 0.003348307451233268, Test Loss: 0.0057338206097483635\n",
      "Epoch 36, Training Loss: 0.008950294926762581, Test Loss: 0.00480262516066432\n",
      "Epoch 37, Training Loss: 0.0038404769729822874, Test Loss: 0.006408466957509518\n",
      "Epoch 38, Training Loss: 0.006069470662623644, Test Loss: 0.006894809193909168\n",
      "Epoch 39, Training Loss: 0.006413004826754332, Test Loss: 0.006062929984182119\n",
      "Epoch 40, Training Loss: 0.005892549641430378, Test Loss: 0.005690039601176977\n",
      "Epoch 41, Training Loss: 0.004128319676965475, Test Loss: 0.005545423366129398\n",
      "Epoch 42, Training Loss: 0.004902985878288746, Test Loss: 0.00606531510129571\n",
      "Epoch 43, Training Loss: 0.004729522857815027, Test Loss: 0.00943821668624878\n",
      "Epoch 44, Training Loss: 0.005432798992842436, Test Loss: 0.0054138838313519955\n",
      "Epoch 45, Training Loss: 0.0049665081314742565, Test Loss: 0.004785980097949505\n",
      "Epoch 46, Training Loss: 0.006961232516914606, Test Loss: 0.007043430116027594\n",
      "Epoch 47, Training Loss: 0.006341115105897188, Test Loss: 0.008929761126637459\n",
      "Epoch 48, Training Loss: 0.004727419000118971, Test Loss: 0.007745788432657719\n",
      "Epoch 49, Training Loss: 0.005023570731282234, Test Loss: 0.005727128591388464\n",
      "Epoch 50, Training Loss: 0.004594337660819292, Test Loss: 0.009227619506418705\n",
      "Epoch 51, Training Loss: 0.005531613714993, Test Loss: 0.010818535462021828\n",
      "Epoch 52, Training Loss: 0.008116204291582108, Test Loss: 0.007315770722925663\n",
      "Epoch 53, Training Loss: 0.0032594806980341673, Test Loss: 0.007359381299465895\n",
      "Epoch 54, Training Loss: 0.0047987112775444984, Test Loss: 0.0069245570339262486\n",
      "Epoch 55, Training Loss: 0.0031753398943692446, Test Loss: 0.0036106405314058065\n",
      "Epoch 56, Training Loss: 0.0027963982429355383, Test Loss: 0.006845773197710514\n",
      "Epoch 57, Training Loss: 0.0033145949710160494, Test Loss: 0.004781321622431278\n",
      "Epoch 58, Training Loss: 0.004080408718436956, Test Loss: 0.003265880746766925\n",
      "Epoch 59, Training Loss: 0.005926011595875025, Test Loss: 0.006952543277293444\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if(train == True):\n",
    "    best_loss = 10000\n",
    "    model_train = NetworkModel().to(device)\n",
    "    best_model = model_train.state_dict()\n",
    "    epochs = 60\n",
    "    learning_rate = 16e-5\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model_train.parameters(), lr=learning_rate)\n",
    "    test_loss = []\n",
    "    train_loss = []\n",
    "    for i in range(epochs):\n",
    "        for X, Y in train_loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            Y_pred = model_train(X.float())\n",
    "            loss = loss_fn(Y_pred, Y.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        # Test Loss\n",
    "        with torch.no_grad():\n",
    "            for X, Y in test_loader:\n",
    "                X, Y = X.to(device), Y.to(device)\n",
    "                Y_pred = model_train(X.float())\n",
    "                test_loss_fn = loss_fn(Y_pred, Y.float())\n",
    "            print(f'Epoch {i}, Training Loss: {loss.item()}, Test Loss: {test_loss_fn.item()}')\n",
    "            test_loss.append(test_loss_fn.item())\n",
    "            if(test_loss_fn.item() < best_loss):\n",
    "                best_loss = test_loss_fn.item()\n",
    "                best_model = model_train.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss[:], label='Training Loss')\n",
    "plt.plot(test_loss[:], label='Test Loss')\n",
    "plt.legend()\n",
    "datestring = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "plt.title(datestring)\n",
    "plt.savefig(f'./train_logs/{datestring}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in range(len(X_test)):\n",
    "    X_out = model_train(X_test[i].float())\n",
    "    # print(X_out)\n",
    "    Y_out= y_test[i]\n",
    "    # print(Y_out)\n",
    "    array.append((sum((X_out - Y_out)**2)))\n",
    "    # array.append(loss_fn(X_out, Y_out).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[486], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "torch.mean(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(7.9262e-07, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.9129e-06, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.6160e-06, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.3958e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.5100e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.7761e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(2.7996e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.1430e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.2514e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.7277e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(4.0171e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(5.3096e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(5.4564e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(6.4358e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(6.4402e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.4267e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.5749e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.7187e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.9123e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.1020e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.4422e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(9.9288e-05, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0008, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0009, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0011, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0012, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0016, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0021, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0024, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0025, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0026, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0027, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0028, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0029, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0034, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " ...]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006952543277293444"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003265880746766925"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = NetworkModel()\n",
    "new_model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17393026059074954, 0.15832012463898548, 0.1435221372164106, 0.13118807665641602, 0.12046238137451759, 0.10874087224243342, 0.1031937653777054, 0.09729147154096911, 0.09506525800679769, 0.09421256003024978, 0.09224026396833815, 0.08870569884476469, 0.08855946883451067, 0.08777999246879017, 0.08700691314232428, 0.08526109917874099, 0.08492592608002267, 0.08287448853702903, 0.08268984281523434, 0.08173629913393757, 0.0806156516715289, 0.08030542833078752, 0.07998137853442033, 0.07719663917234981, 0.07660553310706562, 0.07614680081421006, 0.0748928689814706, 0.07435553437202302, 0.0743441387494701, 0.07283309644309163, 0.06796361888970465, 0.06754969030463669, 0.06626500946961783, 0.06534005400854295, 0.06504402159190611, 0.06468950980452146, 0.06451748658607906, 0.06431587209992472, 0.06413733739164912, 0.0639420295231086, 0.06370494764264548, 0.06366189663166444, 0.06352570407160514, 0.06347423959709424, 0.06324829596451362, 0.06266319649757485, 0.061737768148822196, 0.06120356839501568, 0.06024819414565587, 0.05949897404715518, 0.05857079350010427, 0.058361545565850666, 0.058198434541753635, 0.05816860561350427, 0.05812279227199624, 0.057592611435209135, 0.05753481968573356, 0.05731098832968319, 0.056025694133792235, 0.055384124631305, 0.054609794498273, 0.05445011768825071, 0.054410379585144, 0.05437847051806661, 0.05398368549658899, 0.05388367349529795, 0.05376191011533305, 0.05289935194289394, 0.05279122414535596, 0.05253724633818027, 0.05183358759191188, 0.05122419065359676, 0.051199861773152125, 0.050959811262937645, 0.050879295196671066, 0.050760145859037265, 0.05057088829120007, 0.050494247768618036, 0.049990256309854264, 0.049828161518696276, 0.04966533681037166, 0.04959977758938986, 0.0489447704027041, 0.04863485726316009, 0.04851445157253569, 0.04841292702489115, 0.047981988424003474, 0.047886560325834236, 0.04782210945588378, 0.047685121992832064, 0.04757061262886678, 0.04756702795875668, 0.04751665821563903, 0.047114287475725616, 0.047059149861599106, 0.04689120805845712, 0.046751920591895965, 0.04671559028047765, 0.046686036061266686, 0.0463527771922254, 0.04614208879684745, 0.04602525659597742, 0.045922490877699285, 0.04588076921917325, 0.045733853233519695, 0.04549453373950022, 0.045477652121339654, 0.04529864973882993, 0.045207106261580955, 0.04518852898243509, 0.045136563401630816, 0.04508690897096101, 0.044754959782029265, 0.04468479716720686, 0.04463983226889665, 0.04454590034464441, 0.044381725967176336, 0.044369908362887255, 0.04431356576074427, 0.0442396276577693, 0.044201976948284635, 0.044139976354852034, 0.04402102687606735, 0.044008420978717, 0.04379068533912204, 0.04366919554944807, 0.04360393438568218, 0.04345800245179342, 0.04344473847245173, 0.04343880944478492, 0.0432475510199412, 0.0432310872667654, 0.043200703561184, 0.04292667337407148, 0.04269505808249057, 0.04266326419382754, 0.04263229050768084, 0.04250699505979686, 0.04249788768980404, 0.04242224568599818, 0.042373833762441505, 0.04226158697728141, 0.04208364867766278, 0.041992065331653054, 0.04195207229224321, 0.04168216961883245, 0.04159630890319131, 0.041507910022076405, 0.041433330721185185, 0.041383547751489606, 0.0413835204751432, 0.04125094163259784, 0.041244078093324525, 0.041218978972411065, 0.0412084637195828, 0.0409368799265605, 0.04090346311516784, 0.04067860475230282, 0.04065073927331448, 0.04048636030593736, 0.04037227677842767, 0.040320462447515346, 0.04029945436234648, 0.04006711575363047, 0.04004761202254466, 0.04003643295660929, 0.03997987645086718, 0.03965209486961298, 0.03959150457539567, 0.03939366425100561, 0.03934005282066137, 0.03923876391730477, 0.03917716112520454, 0.03914677667392951, 0.03899920451608058, 0.03895510575191592, 0.03879938155367739, 0.03844419313034485, 0.03818051992610956, 0.03797218580749818, 0.03796709131949224, 0.03773139022971465, 0.03755463597390604, 0.03736248983305726, 0.03734735499479492, 0.037257116757994445, 0.03680966114845018, 0.036780353620816546, 0.03666317835651502, 0.03664125997117661, 0.036358776498526306, 0.03635129323321351, 0.036302102716116884, 0.03623161491460412, 0.03619715970568852, 0.036084895854750935, 0.036066671784648605, 0.0357944906555964, 0.035770139353263945, 0.035662129292268904, 0.03561598175431799, 0.03542386748845973, 0.035389415816042234, 0.035379590528831995, 0.03523252366052805, 0.0351809876143254, 0.035157987333616844, 0.035079871325619405, 0.03495342747958727, 0.03493890593447074, 0.03484279132058483, 0.034738057905331694, 0.03466221299356306, 0.03461241902080957, 0.03459642432156648, 0.034572115925278896, 0.034542054909670876, 0.03449917136881493, 0.034453326519157175, 0.034437514472907396, 0.03442518587663965, 0.034423454704419744, 0.034327175352364306, 0.03432159830242412, 0.034284074327384645, 0.034273751123393155, 0.03426585284282233, 0.0342329096968516, 0.034168403572753005, 0.034105204000792116, 0.034086204815367484, 0.03388411394768513, 0.0338807803862435, 0.03382776624461441, 0.03376327649300711, 0.033559591445863304, 0.033530152211996796, 0.03348540998104652, 0.033438154402991915, 0.033373262545090265, 0.03333982854649534, 0.033304592930690394, 0.03324156794433331, 0.033210736438930605, 0.033125989323255035, 0.03309881796209294, 0.03307871083800614, 0.03291905481568821, 0.03283297478982126, 0.03270193716060975, 0.03262051600026283, 0.03256814523101264, 0.032540782199068925, 0.032474474550761946, 0.0323964343503064, 0.03236925319885081, 0.03235117773392629, 0.03223786464985602, 0.032219603089936905, 0.03208037946901567, 0.03176005822368098, 0.031725036144672404, 0.03161648874339591, 0.031587865402392806, 0.031547122611550044, 0.03135553108772857, 0.03119583618728058, 0.031175477280790585, 0.031164160319435818, 0.03115812696808394, 0.03108652681302718, 0.030978907045696245, 0.030915125707390197, 0.030871776498083963, 0.030678267329964887, 0.030576618456527375, 0.030549890940446574, 0.03054735949505412, 0.030354830967933486, 0.030339948938212787, 0.030321487842490145, 0.030216484109022446, 0.030203038618087322, 0.03009374361327817, 0.03000253177926131, 0.029962974746960063, 0.0299407005037117, 0.02991958685564141, 0.029816645790287675, 0.029791227189695443, 0.02970376840407393, 0.029696246783298064, 0.029632733670285606, 0.02961489551675553, 0.029614371738297573, 0.029492189688106053, 0.029378584745383497, 0.029230935761908664, 0.029202891906603263, 0.029035471348293734, 0.02883568166495863, 0.028680648487478776, 0.02857458676028955, 0.0285208532336921, 0.028459788551868075, 0.02837069245556437, 0.02835001231079392, 0.028321572090816847, 0.02827614021533951, 0.02821469854158786, 0.028181848843401358, 0.028143973311769988, 0.028119375750796136, 0.02809255792832865, 0.02808583452988772, 0.02805267554899996, 0.027986866831144906, 0.027847478413157413, 0.027813887361080498, 0.027791303000045106, 0.027758181064626592, 0.02774301519208908, 0.027742066049194644, 0.027719363749803744, 0.0277033344896685, 0.02768548253431559, 0.027635999912877105, 0.027545038896203456, 0.027525924248827438, 0.02744413398712287, 0.0273919115195063, 0.027391416203217552, 0.027263896979016967, 0.027253657637222272, 0.027203837432815077, 0.02720176294945379, 0.027197284475129424, 0.027181312623919242, 0.027066658166922587, 0.0270559122349842, 0.026907450907548015, 0.026754355065597854, 0.02671927739504419, 0.026684358280051484, 0.026611904295891567, 0.026559660829737486, 0.026520634293732952, 0.02642814650578587, 0.026395711076837018, 0.02638977076896481, 0.026283430539055408, 0.026177805891520103, 0.026093661773886317, 0.026052877237589124, 0.02603827825479565, 0.0259359332395671, 0.025908312817369338, 0.025881504426907558, 0.02577155965698648, 0.02575859178272886, 0.025750713854498668, 0.025711147314252825, 0.02570080540991111, 0.025536084948249476, 0.02548262133445848, 0.025455400776288252, 0.025344614559030275, 0.02532254593222746, 0.025298536775772453, 0.02527950052503402, 0.02525051748473695, 0.025212365566926846, 0.025211867379189293, 0.025207475830722102, 0.02520354667543513, 0.025103735704479026, 0.025054331539572386, 0.025032207728658537, 0.024956229724962458, 0.02495528263751557, 0.02482568494929009, 0.024813672118794632, 0.024798099910101533, 0.02478214701881367, 0.02477048714385057, 0.024751079276650413, 0.024738816027604783, 0.024708497932400056, 0.02470758254702467, 0.024700153498445385, 0.024691248165783542, 0.02460084657576371, 0.024589202860224275, 0.024562486583197672, 0.024475057229748732, 0.02446121218506297, 0.024457352246782152, 0.024417769963405188, 0.0243434217416833, 0.02434273676706729, 0.024294588512739742, 0.024260316229616042, 0.0241220605963826, 0.024116184578268866, 0.0241104109475915, 0.024042008299132625, 0.024000100105578494, 0.023947185528041228, 0.02392423011316282, 0.02391513328349583, 0.023903262122856508, 0.023893976444158572, 0.023804800276202222, 0.02376070029243508, 0.02374640024421921, 0.023730708821657835, 0.023668074208866952, 0.023597320015099205, 0.023583733228561363, 0.023583266859405802, 0.02357083653976935, 0.023562592145233673, 0.023532606430781727, 0.02348943689618231, 0.023420170591459375, 0.02338751356397785, 0.02337001847273864, 0.023368876022152166, 0.023262632482503248, 0.023239207929355007, 0.023175385136912054, 0.023155741373920926, 0.02313969848281844, 0.02309233277381614, 0.023047108823753413, 0.023032630590913056, 0.023028207265675643, 0.022991184980111802, 0.022963431608755174, 0.022856134220118708, 0.022837136221497092, 0.022823807318021767, 0.02275656055214806, 0.0227492821768402, 0.02274778045648254, 0.022694017597016163, 0.022690515208040087, 0.022685186486345727, 0.022636454135194536, 0.022600669360059333, 0.022588552656139443, 0.02258519016989867, 0.0225665133012149, 0.022530425429170747, 0.022506750654304374, 0.0224564901170202, 0.022455978216848627, 0.022436296681827186, 0.022421443884999143, 0.022398265663638187, 0.022369771006474106, 0.022278534009557434, 0.022235067025816686, 0.022224063080462306, 0.022218010529995565, 0.022206332626565153, 0.02217669826168781, 0.02216169896034456, 0.02211187808081672, 0.02209882735506243, 0.022096904070828108, 0.02206940217789266, 0.021994216718399948, 0.02197990540790222, 0.021979138220479748, 0.02197446980239169, 0.021948902949128976, 0.02193776872387474, 0.02192757062878067, 0.021811818901212875, 0.021807102227136915, 0.021805302084908433, 0.02176175350855606, 0.02175873699500686, 0.02164850617031314, 0.02163351382247594, 0.021619157017496754, 0.021615301016990322, 0.02160762265511703, 0.02159200996024329, 0.021554919774689738, 0.021549008937174076, 0.021349369264440973, 0.021326683650347178, 0.021325246136062785, 0.021320591343343444, 0.021279632431250965, 0.02121525249792062, 0.02103247917488696, 0.02102826188213404, 0.021007592088793055, 0.0209732530229884, 0.020963368517184184, 0.020864670108674654, 0.020860051565843994, 0.020794505105489004, 0.020792824609446155, 0.02076299494107686, 0.020750312885442546, 0.02070511486129997, 0.020687271195313328, 0.020659392196619088, 0.02061989218514753, 0.020609380567408034, 0.020579504428774792, 0.020540224735595265, 0.020537989251630043, 0.02048097263201259, 0.020468170222078197, 0.020450833137988275, 0.02042116618290476, 0.02034978901790662, 0.020344336701183137, 0.020328701649090106, 0.0203239877342202, 0.020284016640726057, 0.020205125114040604, 0.02016447953391491, 0.020158805168796225, 0.020109543332736783, 0.020099470549323078, 0.020097804794855782, 0.020078665485795, 0.020077347393594774, 0.020032891927608203, 0.01997419374971785, 0.019955899027529013, 0.019953568746302042, 0.019935402762686197, 0.01991698580791766, 0.019850664377757052, 0.01981155199952551, 0.019775668865437593, 0.01976658023204283, 0.019739143782356326, 0.019732739773973856, 0.019697840361697104, 0.019661689403017293, 0.019635004547220353, 0.01963221945350291, 0.019619774341376118, 0.01959130614454526, 0.0195767985126559, 0.019560785345944718, 0.019543786983717223, 0.01953480536678873, 0.01951945712550755, 0.019472314442643225, 0.019441910625361193, 0.01941219582767198, 0.01930175937810264, 0.019292989426386173, 0.019251922380618597, 0.019251776767214433, 0.019197146494324514, 0.019163940462447623, 0.019111866488701855, 0.019105598043024367, 0.019094852409025292, 0.019087277055713996, 0.019086619329722998, 0.01908081643507359, 0.019025081034722023, 0.018983885481380264, 0.018947511257826833, 0.01894595003101444, 0.01890990497503222, 0.018857774358741825, 0.01882055951200275, 0.018811952378616197, 0.018809643619923738, 0.018789403604339196, 0.01878275939603704, 0.018758860771711686, 0.018729662037446675, 0.018703142674416647, 0.018671770842206642, 0.018621546534247746, 0.018594340354706817, 0.0185388053699745, 0.01850529332140527, 0.018458675620697192, 0.01843560003084365, 0.018418290717397538, 0.018388833319533643, 0.018342909417956205, 0.018338166965956526, 0.0183153550179865, 0.018253521856895785, 0.01818940464098424, 0.018188856301074124, 0.018131087833026246, 0.018053127905391143, 0.01797733648873554, 0.017976395455870535, 0.017950636969429286, 0.01791898637261249, 0.017909382987751174, 0.017908125462525744, 0.017866176429837666, 0.017824498161901646, 0.017799918048293374, 0.01774079341995731, 0.01768836556414209, 0.01762587543497675, 0.01761679148698257, 0.01759894306705619, 0.017587539671549968, 0.017583422612023836, 0.0175384662341514, 0.01748622315102113, 0.017481653279387676, 0.0174690190589994, 0.01743736868143056, 0.017425644824881376, 0.017423505850048614, 0.017399855089426833, 0.0173919143726142, 0.017386526438573323, 0.0173860311348043, 0.01736280996037387, 0.017357357134281565, 0.017327209818698973, 0.017280386338795885, 0.01727520924649629, 0.017247023548201585, 0.0172205173712799, 0.017215493793350852, 0.017174863711065164, 0.017126833124153213, 0.017068887253054152, 0.017060130757363873, 0.01705539771162252, 0.01701792170688416, 0.01700463526990406, 0.016993554420115825, 0.01696762418110344, 0.016940436420904176, 0.016935898471782434, 0.016924442574572013, 0.016917827978222843, 0.0168722994582306, 0.016834742370404793, 0.01681611835772539, 0.01680261816815442, 0.016802155931792222, 0.01677833496493157, 0.01675999852575186, 0.0167426207073406, 0.016732933496893004, 0.01669905055808167, 0.01668289179832664, 0.016659508064593043, 0.016641644993784083, 0.016640733717164877, 0.01663544840596437, 0.016633728541207256, 0.016614270072776733, 0.016588436996545185, 0.016572695685293123, 0.016558618414709812, 0.016557013264326417, 0.016542883295584294, 0.016456930180502257, 0.016432181211472587, 0.016409446761308396, 0.016409260565212216, 0.01637305575783065, 0.016310019724907754, 0.01630283222304381, 0.016273523988616666, 0.016261832133574454, 0.01626031342403168, 0.016230175386001463, 0.016206086494405136, 0.01619900890213434, 0.016162098398331, 0.01615920960926889, 0.016140149376703217, 0.0161203343196969, 0.01610618228440033, 0.01608251356019552, 0.016073540809407434, 0.016071291447831818, 0.016067058941109352, 0.016033181438402416, 0.01600138062194192, 0.015999734889687624, 0.015995177005389098, 0.01598857270487032, 0.015976875125842834, 0.015945657394697135, 0.015945434597466276, 0.01592841078777725, 0.01592212380025052, 0.015910296838142723, 0.01590943057095998, 0.015890426615898696, 0.01588640683834292, 0.015869607985362945, 0.015852203802068567, 0.01582353464180542, 0.01581220323650443, 0.01578029943648665, 0.015769889177517517, 0.015766760626396648, 0.0157494343889296, 0.015737461526247512, 0.015735563856733806, 0.015725329577327106, 0.015697608199076157, 0.015670258309747134, 0.015632411933696935, 0.015613265165672838, 0.015585468654871175, 0.015526871863938441, 0.015521766048867723, 0.01551682922144975, 0.015466782973363522, 0.015463254459328384, 0.015444911166630628, 0.015439769325990836, 0.015430031303399653, 0.015417553268831569, 0.015416815030133332, 0.015377943379907756, 0.015369312468496205, 0.015359453983425496, 0.01534387856206592, 0.015341711321626695, 0.015320802632958923, 0.015305073178265335, 0.01528478802123636, 0.015257728680306967, 0.015245408628734247, 0.015232510256563053, 0.015214753875806415, 0.015208077052582633, 0.015180780580683425, 0.015171318344098612, 0.015159055001020945, 0.015146678076840602, 0.015125086988476612, 0.015123571088553663, 0.01509596118988677, 0.015032815457008897, 0.015028019388879231, 0.015023200017068099, 0.015018349331885398, 0.015014335185912919, 0.015009938478640416, 0.014993402230314057, 0.014991922153281058, 0.014982221818668645, 0.014976167929373365, 0.014957522434686087, 0.014948254963483901, 0.014942303847403082, 0.014938651709957326, 0.014929432197813512, 0.01492937198120286, 0.014922362257067705, 0.014915042485615254, 0.01491370033618902, 0.014896262283612063, 0.014894393987072955, 0.014874149615290586, 0.01485647875145355, 0.014834473015534115, 0.014817348602217053, 0.014815346072928505, 0.0148059708721682, 0.014805759453092421, 0.014798667406938434, 0.014778079973161308, 0.01477417396160109, 0.014768330255211463, 0.014752154726503498, 0.014749480050896097, 0.014723159128525763, 0.014716851114567414, 0.014693796191573792, 0.014680618672935342, 0.014675852662104619, 0.014667659465303884, 0.014660221414533263, 0.014651452259603097, 0.014610716527525762, 0.01460617483566682, 0.014518244083398277, 0.014515785348156032, 0.014506773407935806, 0.014500400931426146, 0.01447155975581467, 0.014465473303186118, 0.014452974354426091, 0.014440132052966625, 0.01439621651772104, 0.01439035292732777, 0.014388673946494486, 0.014384167847015643, 0.01437884903403063, 0.014368927881189951, 0.014323214413631147, 0.014316085965582832, 0.014281783159837766, 0.014264897309625584, 0.014254223294349085, 0.014231063912509933, 0.014227079774592128, 0.01421843542720899, 0.014204989008575208, 0.014187673601999766, 0.014185824206163343, 0.014182354556657669, 0.01417501707103185, 0.014159745018485263, 0.014157768151996116, 0.01414709862459207, 0.014131996256796184, 0.01412352781525767, 0.01410383185578847, 0.014101602493332178, 0.014071328342012183, 0.014062935300409866, 0.014033110565939148, 0.014032939217537056, 0.014022891803863376, 0.0139706235940113, 0.013961014295564726, 0.01394436104645077, 0.013936377095707627, 0.013913275941270257, 0.0139091051416593, 0.013906865119622957, 0.013882717375301078, 0.013869499440730954, 0.01385907331180129, 0.013820268695108561, 0.013812044361647235, 0.01380667854919437, 0.013798299822282869, 0.013792548581617454, 0.013772942720767536, 0.01374337230754843, 0.013735288899593306, 0.013734166961622135, 0.013726691662384605, 0.01367856717850192, 0.013649991104771596, 0.013649252229613522, 0.013643975483870358, 0.01363619289718095, 0.01362744176096221, 0.013625744417334277, 0.013611320867657444, 0.01361086925252566, 0.013583179815940373, 0.013582934980562006, 0.013574862230309582, 0.01353673586019507, 0.01352086262499883, 0.013520321809419884, 0.013500576962298913, 0.013494257464683192, 0.013480455203017062, 0.01346654184850471, 0.013452828035317707, 0.013451079043751448, 0.013450129413400508, 0.013437706175975572, 0.013429307537977827, 0.013428876931824058, 0.013406426983376227, 0.01339386883277512, 0.013391838831964294, 0.013376979855785835, 0.013371750038544145, 0.013368805124887152, 0.013365706561425482, 0.01334186423782402, 0.013331389225520848, 0.013329676946912622, 0.013327857948819763, 0.013299352973151268, 0.013284318121826687, 0.013283481997116924, 0.013275212720748861, 0.013252513067404732, 0.013226787908938267, 0.013222877131260044, 0.01321731654020197, 0.013204008842983431, 0.013203672042245096, 0.013197338314724739, 0.013188318554101904, 0.013181783941928087, 0.013178147113444824, 0.013155444935793853, 0.013147755869046453, 0.013127009074373086, 0.013121410863906875, 0.013121310230444067, 0.013119379724726567, 0.013118420477355812, 0.013116066908939775, 0.013110203610829013, 0.013101862988651094, 0.013099031800448692, 0.013083460461857608, 0.013053729268808049, 0.01305189217667244, 0.013036119253093361, 0.013034711740876326, 0.013010493024780113, 0.012993289461633369, 0.012990006295777358, 0.012989511444468013, 0.012969574840214113, 0.012955217162056587, 0.012952880934996126, 0.012915195806731967, 0.01291251730001608, 0.012908327662896232, 0.01290350768945423, 0.012893890836191333, 0.012869555134832447, 0.012824877845612648, 0.012791188488908714, 0.012788235387779567, 0.012781438680171169, 0.012774381250257092, 0.012772437107183975, 0.012768743833644331, 0.012764294524093925, 0.012753156082594036, 0.012751091939908437, 0.012748911467136165, 0.012744332830112443, 0.012731448361182281, 0.012724188849170794, 0.01270461453411381, 0.012642332134099543, 0.012637279654128626, 0.012635275983491283, 0.01262948486354732, 0.012619372695700197, 0.012610786081090446, 0.012606237638211448, 0.012592542717602441, 0.01259123028079248, 0.012589768933930646, 0.01258302807882867, 0.012576863679681652, 0.012560057027236058, 0.012557891040164405, 0.012521543441430366, 0.012516487746532152, 0.012476250650678491, 0.012471531152927953, 0.012463227927016735, 0.012452052473798207, 0.01244741844660903, 0.01244379714971428, 0.01240207816580378, 0.012398157026838936, 0.012394915292869391, 0.01239429965911677, 0.012386755101225617, 0.012344138212695132, 0.012333072260958042, 0.01232789690704849, 0.012300976272386598, 0.012298242744854623, 0.012290402082016224, 0.012288079058658185, 0.01227187587896834, 0.012263414702648936, 0.012252725641559537, 0.012241446480975677, 0.012239056565163591, 0.012233849645543773, 0.012218143856321187, 0.012202063647222854, 0.012181653837713313, 0.01216506239172177, 0.012150593543162641, 0.012146074992782408, 0.012139999081043091, 0.012131486305897622, 0.012126259196673433, 0.012123008629570027, 0.012116126732334174, 0.012093183533151548, 0.012091795633310198, 0.012085615657502744, 0.012068510668432487, 0.012068293133676357, 0.012061358930678685, 0.01204926612057089, 0.012046702837414136, 0.012035978466185489, 0.012030395352861992, 0.012026760625141922, 0.012023841736589304, 0.011993027799878932, 0.011979108243159453, 0.011969804194846148, 0.01194878412057931, 0.011939466100192033, 0.011931105795144467, 0.011922664610711304, 0.011919132200909729, 0.01190627207015751, 0.011905538492803337, 0.011900412326905103, 0.011883758310810705, 0.011883573073691638, 0.011874300089977845, 0.011872798856940897, 0.011871472836627622, 0.011865896655205928, 0.011855149967181976, 0.011851435508260094, 0.011812374000241155, 0.011780329480851181, 0.011771658547617754, 0.011748968606469073, 0.011745510188700474, 0.01173348863748544, 0.011729083780202786, 0.01170606757372003, 0.011705012578492156, 0.011701255151196467, 0.011691151247875653, 0.011680046207841108, 0.011679022621385232, 0.011678091126574528, 0.01165443374653361, 0.011652000265932872, 0.011622570707497594, 0.011606616945556331, 0.011575525853463513, 0.011561904642247364, 0.01154012846309218, 0.011534189514981797, 0.011529104363004227, 0.011512175318513741, 0.011480923423803177, 0.011470220983493594, 0.011455454701720748, 0.011448917899970778, 0.011446622247914776, 0.011445837699911806, 0.011429666204112534, 0.01142059687588591, 0.011417035437577463, 0.011416090821787349, 0.011411428003536873, 0.011385666772583604, 0.011385011807890179, 0.011375370297179322, 0.011360418209395037, 0.011318746534085577, 0.011304981953536635, 0.011284214373895419, 0.011284020071976875, 0.0112783886790223, 0.01127734571268569, 0.011273368165816736, 0.011271104613130037, 0.011245147878637231, 0.011240352499301585, 0.011217562460042031, 0.011192813750140453, 0.011186707131473158, 0.011168925938847194, 0.011157006720815519, 0.01113000284670663, 0.0111276536249281, 0.011120071914859428, 0.011109535340301267, 0.011093708281217814, 0.011086570805741703, 0.011084353020954524, 0.011076456983679827, 0.011076096188327663, 0.011072000559106482, 0.011056508252057827, 0.011048319112076628, 0.011044408889753362, 0.011042880403690235, 0.01103565608823846, 0.011008160396273487, 0.011007493796529018, 0.011007141553695605, 0.011005506534378335, 0.010990716513171414, 0.010987333345138618, 0.010984324107259769, 0.010959298781860864, 0.010958957638438254, 0.010950669223372043, 0.010930678322400186, 0.010927273388293806, 0.010922573105797882, 0.01091744349146571, 0.01091424276188978, 0.01088845989874554, 0.010876874291676945, 0.010853276374931067, 0.010839600919473755, 0.010818373844322904, 0.01081700128468174, 0.010772896435943017, 0.010760206413064818, 0.010745518384028794, 0.01073830536677047, 0.010727292181533999, 0.010726828249707223, 0.010721809702917903, 0.010695206650812621, 0.010693377254256484, 0.010691194106730476, 0.010686374257821473, 0.010676321078811633, 0.010663852060570383, 0.010634959673411621, 0.010630063674252998, 0.010594691640391675, 0.0105784785707339, 0.010575634087834272, 0.010574327390305178, 0.010565843908941356, 0.010527369551592416, 0.010510038269000313, 0.010493442314502664, 0.010466105163677422, 0.010444530397929865, 0.010438818958990249, 0.010435171770283047, 0.010425178400954986, 0.010403147845676818, 0.010388184672296543, 0.010381263246349031, 0.010371056714581215, 0.01037080836710358, 0.010364231498563579, 0.010354109862788216, 0.010332243007930113, 0.010326241216280431, 0.01032433626820124, 0.010307148039180137, 0.010289969705873902, 0.01028445154745379, 0.010277384005366385, 0.010263864369525194, 0.010256026132981324, 0.01025423409779987, 0.010234822112707221, 0.010228094469218778, 0.010219920557770934, 0.010198648272786964, 0.01019279200557723, 0.01018846190269418, 0.010187849425325085, 0.010164345059205094, 0.010163717914169687, 0.010160453025444249, 0.01015370153832795, 0.010148986127592373, 0.0101353078193407, 0.01011514855408546, 0.01009994411405048, 0.010096149973084353, 0.010086613758453317, 0.010083417479723236, 0.010082696991832391, 0.01008101317289911, 0.010064183250806161, 0.010059127588829849, 0.0100399678666388, 0.01002410650276921, 0.009998843703142806, 0.009993158430819566, 0.009970748848059308, 0.009970373387546968, 0.00996809611242912, 0.00996148105120028, 0.009954010123201273, 0.009939313775262377, 0.009936355540179426, 0.009898910621255497, 0.009883666049017761, 0.009873945077183595, 0.009865493491747835, 0.009865380488903416, 0.00984922728742612, 0.009844837610808363, 0.009841665451376566, 0.00983902515185877, 0.009800686198299937, 0.009798773990132103, 0.009775811884534176, 0.009769536739551853, 0.00976164845726123, 0.009742289995485154, 0.00973944774672188, 0.009737819914798003, 0.009736280577917774, 0.00973145707592429, 0.009723501060743059, 0.009717822651939238, 0.009709573463550924, 0.009704727088905409, 0.009689654526404384, 0.009686548363939479, 0.009686026180967694, 0.0096533480954584, 0.009652116780509487, 0.009644110020087719, 0.009622401658652045, 0.009618866644577857, 0.009617666958084976, 0.009587640314217381, 0.00957385281044124, 0.009569797032325638, 0.009568808027959359, 0.00955853280431695, 0.00954351654715858, 0.009542381776175123, 0.009533215950244556, 0.009525014282505812, 0.009523450565944116, 0.009522875953470095, 0.009521341396784837, 0.009508327399381563, 0.009496496527829556, 0.009493766672791084, 0.0094922358771481, 0.009474296760875406, 0.009472224316167205, 0.00946082920373729, 0.00946017248791213, 0.009451607715879308, 0.009451249672160721, 0.00942863315332602, 0.009426390380236353, 0.009420144694759193, 0.009417573016950564, 0.009417121356639076, 0.009398177140910556, 0.009392742882004862, 0.00938970140869812, 0.009360407705907688, 0.009354629896203833, 0.009354282850599048, 0.009347958311038454, 0.009317953751352978, 0.009314582334044141, 0.009309353444275439, 0.009303739716725287, 0.009298637057264211, 0.009289835691247795, 0.00926567066032304, 0.009211948844025809, 0.00920579628258875, 0.009168479205146166, 0.009163177743267673, 0.009161894167795046, 0.00915825673321747, 0.009138405234105631, 0.009130062446395967, 0.009110233403430958, 0.009108637019906869, 0.009105337958654982, 0.009082761078488408, 0.00907222699740152, 0.009069783059403686, 0.009067146562195925, 0.009051248664504038, 0.009040668300945576, 0.009032487711642011, 0.009026890977665835, 0.009002064065298646, 0.009001218397882461, 0.008966317078802221, 0.00896142830054517, 0.008943432011706226, 0.008939437245752756, 0.00890599050502399, 0.008893947159977888, 0.008878707801321542, 0.008852825221878587, 0.008825184452151864, 0.00882106902990695, 0.008804364545406613, 0.008794193085557914, 0.008791410879099558, 0.008760555351143883, 0.008747116530859023, 0.008744590055261483, 0.00874134628392144, 0.008741055029058267, 0.008735562105956603, 0.008735368218093474, 0.008734795537289855, 0.008723759272309933, 0.008721701847166134, 0.008712852857336853, 0.008708031707414438, 0.008704389908307117, 0.008688452181018387, 0.008681254659409806, 0.008676598226534148, 0.008669616880163046, 0.008665156793114137, 0.008658488269469324, 0.008652819194136385, 0.008644305536291986, 0.008636156961124198, 0.008635213247095687, 0.008629543060382711, 0.008628435702980369, 0.008620645509808915, 0.00861809561854352, 0.00861212062476557, 0.008610005560769296, 0.008609836884868272, 0.008603448344511488, 0.0086012772818456, 0.008598634437208947, 0.008592725601930702, 0.008592596410546782, 0.008591508824753532, 0.008591023334182792, 0.008588090335795337, 0.008577842470982117, 0.008573439837210166, 0.008564955177025461, 0.008559379924763145, 0.008559370453083888, 0.008552970085388875, 0.008523478704044286, 0.008522017162841304, 0.008515205510349597, 0.008504912256036619, 0.008500300425643023, 0.008496614086275368, 0.008496180324294557, 0.008484460082675605, 0.008478920715612218, 0.008474529816695518, 0.008473588627186258, 0.00847235342420654, 0.008460256101291301, 0.008452231728540507, 0.00843410347913745, 0.00842631300015837, 0.008424870113208601, 0.008424340642942675, 0.008418300201510142, 0.008411598863483099, 0.008404388097625962, 0.00838804611587392, 0.008388043954442957, 0.008370566884002338, 0.008367351804493413, 0.008364042466734762, 0.00836342176842237, 0.008357535307007162, 0.008354902710119523, 0.008351618975296363, 0.00834000625185954, 0.008338659100585797, 0.008335553254025666, 0.008326181805224644, 0.008316200987100448, 0.008308497479572269, 0.008293633301945486, 0.008290095746596777, 0.008284977062343048, 0.00828029024442158, 0.008278989710666658, 0.008260006475100284, 0.00825759271653643, 0.00825713330301708, 0.008255461317667492, 0.008244460101754392, 0.0082400572211429, 0.00819339887988027, 0.008190412713323459, 0.008186263136128781, 0.008181662225519047, 0.008168000042365758, 0.008156696030764837, 0.008154674212092018, 0.008148359107348666, 0.008145902452408772, 0.008137691283309084, 0.008122846487380138, 0.008122299321464497, 0.008117029551998368, 0.008076637113717259, 0.008070992342999747, 0.008068185465407714, 0.00806269031249155, 0.00805605947253472, 0.008051672433999813, 0.008047205621099295, 0.008041348576923166, 0.008027783581899449, 0.008026490641908288, 0.008020865947030803, 0.008014795582436757, 0.00800890091361264, 0.0079954806254336, 0.007956060126100412, 0.007944828813783167, 0.007927298210084532, 0.007925921757681106, 0.0079156343379635, 0.007915167524929963, 0.007914680570721568, 0.007895186781270862, 0.007881210775400039, 0.007874507691384026, 0.007868613335491612, 0.007864550460596947, 0.007861557226234042, 0.007854781883956753, 0.007850382190415676, 0.00783574990832783, 0.007826071420525852, 0.00781301002724364, 0.007808594272154234, 0.007800461703754166, 0.007796183317278202, 0.007771482458414322, 0.0077702211868428935, 0.007760680945787415, 0.007760391527528537, 0.007759048588155891, 0.007751711245880685, 0.007751238851137743, 0.0077413881513108485, 0.007738087041464361, 0.007737530925857672, 0.00773653344561021, 0.007732952605295198, 0.0077220758907463145, 0.007711089305115899, 0.007710154959381781, 0.007704257083600888, 0.007700250137074959, 0.0076923989510879805, 0.007683296013514065, 0.007682264643734567, 0.007677223382697691, 0.007672550447656148, 0.00766992184051956, 0.0076694751609834, 0.007669020691862941, 0.007662027474859693, 0.007642058328872545, 0.00763951301426802, 0.00762672065396006, 0.0076170508292821215, 0.007604092236353759, 0.00759000833866309, 0.0075876376586066045, 0.007573764488618872, 0.0075633226313420975, 0.00756192580800168, 0.007555098435923505, 0.0075456458252521775, 0.007538036504541261, 0.007532109401560176, 0.00753166571012889, 0.007526714562330993, 0.007509776363434155, 0.00750434064116107, 0.007484714013920095, 0.007482021746128043, 0.007479477008226133, 0.0074736961915835036, 0.007458149580944447, 0.00745195833079133, 0.007438259028883795, 0.007436523756875259, 0.007428347536960724, 0.007412039727366467, 0.00739052509095305, 0.007387109633394491, 0.007377312314510096, 0.007363905445891082, 0.007348805920936466, 0.007343154518069838, 0.007341873365674839, 0.007328470522813189, 0.0073074808989929425, 0.007301011700147598, 0.007291589071634876, 0.007291516369378558, 0.007281047194753505, 0.007267012521148777, 0.0072598444710155795, 0.007252618051571405, 0.007244156252279628, 0.0072331552493914274, 0.007230104085241177, 0.007226118729315034, 0.007225184484652515, 0.007217657153404116, 0.0072129392231409, 0.007211484856568954, 0.007195904073945464, 0.007175318952964596, 0.007165028022561894, 0.0071626442814190505, 0.007148705479120102, 0.007144729203973632, 0.007122919789965832, 0.00712008765309414, 0.007118733636261192, 0.007109262699545503, 0.007102213660016254, 0.007094489225111546, 0.0070761538200364215, 0.007069546828897601, 0.007065636011042898, 0.007058542895281742, 0.007043941400554592, 0.007041657434972388, 0.0070318731239906885, 0.007031300678084139, 0.007029367730008962, 0.007028379030427332, 0.007025706653831445, 0.007019587762400551, 0.007008038069487707, 0.006989644836833332, 0.006982502402091917, 0.006976100035713416, 0.006974388852516819, 0.0069550941554424005, 0.006954296356748935, 0.006953447289830756, 0.006951672031853159, 0.006944564776153456, 0.006930798102282632, 0.006927943297798365, 0.006924749798179641, 0.00691471262265966, 0.0069139332757316325, 0.006913855582874174, 0.006901943040847743, 0.006901932135665603, 0.006886429624313368, 0.006886305935878103, 0.006885636588274036, 0.0068757874454803865, 0.006873907682962489, 0.006868800275676782, 0.006859624294273804, 0.006858516161718471, 0.006852423975423132, 0.006850567824341962, 0.006845518581024557, 0.006843915850543534, 0.0068387384185003425, 0.00683433746753145, 0.006831879963673108, 0.006815911614690645, 0.006813734429877968, 0.00679838824052845, 0.006798105227567585, 0.006786097975176885, 0.006764395495870308, 0.006757084720026541, 0.006745833630278928, 0.006731811233240462, 0.006712362020303253, 0.006712265827351654, 0.006710924396825113, 0.0067052042841956785, 0.006685457504185827, 0.006670464579897022, 0.006652631256530588, 0.006647751277434138, 0.006625687666040564, 0.006621410866277414, 0.006618123736885179, 0.0066151490336443675, 0.006611732902785424, 0.006588285110830457, 0.0065841257352045055, 0.006580135120387667, 0.006573158908496837, 0.006559256148964676, 0.006552973036188626, 0.00655104991680387, 0.006529901328552272, 0.0065265247396608375, 0.006523315348974667, 0.00652312222778605, 0.006509192979131566, 0.006503002351278365, 0.006486538526895408, 0.006485320580925892, 0.006477973241615234, 0.006462600875576498, 0.006460473915324812, 0.006436126054073632, 0.0064323662512445505, 0.006422457044836264, 0.006414999607038484, 0.00641061391596886, 0.006398645621201443, 0.0063984342361693885, 0.006372330413099057, 0.006357302439703238, 0.006348142771885744, 0.006343848865529177, 0.006336676064167931, 0.006334597734558212, 0.006319844152278938, 0.006315102339913621, 0.006308152126851736, 0.006299115679898446, 0.006297565885004261, 0.006297524093093247, 0.006290008991265857, 0.006287076210629128, 0.006275527049101069, 0.006267662358574037, 0.0062674601591758685, 0.006265856337473675, 0.006258860631418449, 0.006239128883670087, 0.006236321409904764, 0.006227671372657982, 0.0062261112361536, 0.006212132439560417, 0.006208664595699485, 0.006202046512355654, 0.006193644711267717, 0.006187955353014379, 0.00616880838541655, 0.0061574432445153, 0.006150172367502106, 0.0061470922892725545, 0.00614652782219679, 0.006143506854806765, 0.006142414363656863, 0.006137980318541322, 0.006132092650920141, 0.0061317776299413184, 0.006123911552468108, 0.006116392281438294, 0.006112849017402425, 0.006112754104366196, 0.006111883049688672, 0.006102636314147881, 0.006100975830398985, 0.006071478508557948, 0.006066429949758695, 0.006061362860210778, 0.00605350180736006, 0.006047489878558432, 0.006047144389415645, 0.006042876872412173, 0.006037897315216507, 0.006027472146496158, 0.006027019142794075, 0.006021121710665446, 0.006009783070705047, 0.00600648626223069, 0.006003754285525528, 0.006002625753927006, 0.005994877416695049, 0.005993194167060508, 0.005976878007766671, 0.005974918624428219, 0.005974836840976678, 0.005973144312817814, 0.005947835840667948, 0.005945676188409301, 0.005943698986129359, 0.0059275190030713115, 0.0059118403042467665, 0.0059089098208757445, 0.005904254292132923, 0.005900689600915831, 0.005887836461780677, 0.0058842012221372655, 0.005873013909331588, 0.005865795349547107, 0.005855525096830339, 0.0058370302730929805, 0.005836479474224863, 0.0058288502439915, 0.005821543595683739, 0.005815576473435537, 0.005808468139375911, 0.005791651575825766, 0.005784594630877981, 0.005777089748477335, 0.005771472812345751, 0.005770529626722207, 0.0057655004363396725, 0.005744048771560151, 0.005739751347437948, 0.005721766721652727, 0.005721727892084012, 0.0057079973331575495, 0.005705449092226806, 0.005697665608509909, 0.005692810461982379, 0.0056839275658693515, 0.005681981175752038, 0.005680923852748961, 0.005679912271761226, 0.005669440701944654, 0.005646606056504563, 0.005621989142904309, 0.005609399822255764, 0.0055912160957989855, 0.005590619209454218, 0.005590597969756197, 0.005571111783734146, 0.005569013102201298, 0.0055645160350107645, 0.005561771476940943, 0.005555883747386841, 0.0055368539235495905, 0.0055351987057828305, 0.005532731593007414, 0.005519562949576075, 0.005512500175347512, 0.005502577982979736, 0.00549592732626778, 0.0054874805685452025, 0.005487248276211762, 0.005482430577706298, 0.005472649838174666, 0.005464458422877662, 0.005463585756381337, 0.005456885316871081, 0.005454548728261815, 0.005452778677805719, 0.005444829034977859, 0.005439562825490174, 0.005438703607189318, 0.005438396644450476, 0.005431617495799135, 0.005420138583091483, 0.005419659604344981, 0.005419054789182184, 0.005385893806692772, 0.005371211589811366, 0.005368737108233474, 0.005362149948087388, 0.00535989848665556, 0.005356463547675827, 0.005344247134213752, 0.005337055900475915, 0.005325775255178591, 0.0053115552377334604, 0.005310635339697207, 0.005307484666844758, 0.005306653611404318, 0.005277270165630535, 0.005276157564641465, 0.0052680439562328785, 0.005250483682997948, 0.005241950700324571, 0.00522916740683115, 0.005200046397994051, 0.0051961547915535256, 0.005174156114384374, 0.005165547636189387, 0.005154715729248317, 0.00515429895399062, 0.005146891465095583, 0.00513533825372396, 0.005132054827483554, 0.005115552990474004, 0.0051137286266732685, 0.0051107532359981, 0.005107485359466866, 0.005104056024931355, 0.00509836053000559, 0.005097510958886754, 0.0050939053527854945, 0.005086614153873821, 0.00508373097050171, 0.005078433236702255, 0.005072375536675639, 0.00506386874060632, 0.005061343616249464, 0.005054342537518057, 0.005042137714254302, 0.005040043568114396, 0.005033515709751232, 0.005024829211507665, 0.005018478108077215, 0.005017312964302317, 0.005015586354699047, 0.005014509732774556, 0.005013790697653982, 0.005008935461998269, 0.005003368422823967, 0.005000689708909893, 0.004998372856860521, 0.004992829015855756, 0.004988034694001261, 0.004984226504883076, 0.004984202034333505, 0.004976578043612104, 0.004975072753125642, 0.004969931023577682, 0.004938381824374651, 0.004933549094597603, 0.004918986273392258, 0.0049079085917957165, 0.004901932016278998, 0.004893946488336769, 0.004890313588772884, 0.00488713875730879, 0.00487901068310806, 0.004867708567338101, 0.004867484582266434, 0.004867445753862589, 0.004857237259552865, 0.004853223608857165, 0.004842383488267835, 0.004827356904508932, 0.004820070368549138, 0.00481649087726339, 0.004811143210924597, 0.004808665022569302, 0.004804981237124336, 0.004800704398882036, 0.004798605078987067, 0.0047981643770884505, 0.004793129449489735, 0.004785356028875922, 0.004782273174226461, 0.004777509291616971, 0.004767174282043071, 0.004766408842731799, 0.004759454565259921, 0.004754454962624242, 0.004743128883634432, 0.0047399461208149675, 0.004738435955366718, 0.004734265637726969, 0.004732192094283665, 0.004728752120604013, 0.004723200629012081, 0.004720233122911132, 0.004710867203171033, 0.0046997493726554426, 0.004688139868183796, 0.004681916702148381, 0.0046679322949817, 0.0046621179540499305, 0.004643360891240039, 0.004643298608157511, 0.004642939612966107, 0.0046305615837935275, 0.004626983661078863, 0.00461694320159992, 0.004603352953895633, 0.004597587421144787, 0.004596653187890636, 0.004585654502978133, 0.004573289755502562, 0.00457134989587985, 0.004564129329702341, 0.004561147269967403, 0.004558745343918171, 0.004557953075016254, 0.004552520806372955, 0.004552357354608282, 0.004552156576320248, 0.004550915588320624, 0.004550444500503504, 0.00454852369903932, 0.0045447897535991705, 0.004541037441526279, 0.00452579483521881, 0.0045142084123435365, 0.004512481148076856, 0.00451214723207693, 0.00450857136372143, 0.004500280488544638, 0.004490254814270825, 0.004489894453558532, 0.004478814226356103, 0.004473603617621736, 0.004470170247421056, 0.004469465536644823, 0.004435194817593618, 0.004435136462729049, 0.004427651426122888, 0.0044243012121701055, 0.004408474848176113, 0.004403026789233838, 0.004396554189102881, 0.004392752368135229, 0.004383590286292805, 0.004382029659858767, 0.0043798086840872285, 0.004377819862556715, 0.004377021268639462, 0.004366630213143158, 0.004361583918079748, 0.004346885496157604, 0.004341589297810054, 0.004327859056957992, 0.004320616283705793, 0.004315502677278737, 0.004311722178169411, 0.004311047359974985, 0.0043043985379080845, 0.004301673640997447, 0.004297617183547271, 0.004296803587224668, 0.004295018881972134, 0.004291921088194663, 0.0042883341234380475, 0.004281545716127168, 0.004279826934282412, 0.004276101651797948, 0.004274810248599351, 0.004271778057364243, 0.004253504386379842, 0.004246968787569896, 0.004238893602643831, 0.0042343350840756706, 0.004222834268761588, 0.0042154122148370336, 0.004215380650579379, 0.004207849476255293, 0.004207254436200986, 0.004188702816806194, 0.004186242592074767, 0.004143904721361412, 0.004143633777575923, 0.00414251110106775, 0.004140925466219071, 0.0041349248390226785, 0.004133443216688853, 0.0041224432403094285, 0.004118677660867282, 0.00411675828827353, 0.004107823283960641, 0.004104771856727354, 0.00409571263484815, 0.004094050999323197, 0.004085958313584306, 0.004080677514339948, 0.00407865368007661, 0.004065586485484291, 0.004064776437466507, 0.004059406749345372, 0.004050302468406936, 0.004049984957429566, 0.004048344854354301, 0.004043694746969018, 0.004035083229459625, 0.004031035392540729, 0.004020227616061911, 0.0040187807583456255, 0.0040095036846927124, 0.004005701220500602, 0.003986978577052141, 0.003971109760707335, 0.003968318783201754, 0.003963633491663354, 0.003957267939453583, 0.00395030186632658, 0.003944700085872646, 0.0039413098403869185, 0.0039403229820942935, 0.003925721361844461, 0.003911178041921216, 0.003909969970391874, 0.00389605984033933, 0.0038947402584328457, 0.0038886571773319835, 0.003884748535782919, 0.0038671218091541333, 0.0038653175722381614, 0.0038651370368910534, 0.003861613448966105, 0.0038570729389911136, 0.003848775219696337, 0.0038452319397529883, 0.0038422547990249146, 0.0038409377227979864, 0.0038398362647221428, 0.0038385892922067023, 0.0038371820154847994, 0.003828633244317259, 0.003828347770767798, 0.0038265216353254787, 0.0038241062762689416, 0.0038164265311759994, 0.0038127842897510127, 0.003801987692052293, 0.0037979020065927456, 0.003784325392763446, 0.003749846633085468, 0.0037387064185391097, 0.0037292141704713564, 0.003721840991777594, 0.0037204367288361244, 0.0037202013077870903, 0.003719667597856462, 0.003718898614754477, 0.003709826318325254, 0.00370836229796904, 0.0037006476275344017, 0.003700595746277612, 0.0036991920089650228, 0.0036959042556835935, 0.003687433888253295, 0.003666118335124741, 0.003657655411368433, 0.0036546842839509765, 0.0036535858070902215, 0.003648212676760481, 0.0036369080400275836, 0.0036357833979798766, 0.0036302258654875796, 0.003623532766724694, 0.0036080309582667935, 0.003604536633539577, 0.0036006016170030803, 0.003593774207789888, 0.0035879105482191516, 0.0035808129824057323, 0.003577251505260025, 0.003575242177204446, 0.0035561396266262997, 0.0035459452693702488, 0.003545666667923545, 0.0035412426514926307, 0.003540491734040935, 0.003536473784359963, 0.0035182186601232113, 0.0035097208272922174, 0.003505661145460677, 0.003504319117080064, 0.0034987960718369958, 0.003498108535510614, 0.0034861056106394667, 0.003481971289934032, 0.003473279878134554, 0.0034530402787306346, 0.0034317887053601005, 0.0034253855256670537, 0.003419878004211587, 0.0034190797196048768, 0.0034188516458290097, 0.003415922222104916, 0.0034101903765956366, 0.003406050837901437, 0.003405686439858056, 0.003404503017027183, 0.003401533436464448, 0.0033986191053127315, 0.0033855913952577873, 0.003378158218491624, 0.0033653792363432045, 0.003362283045770854, 0.003360212520982365, 0.0033459167264590214, 0.0033453301943026166, 0.0033380276645188344, 0.00333110470076843, 0.003322443303689313, 0.0033175877548945517, 0.0033138324951189012, 0.0033099204035727386, 0.003302424708459191, 0.0032835848086272663, 0.0032790227129344944, 0.0032687186645349426, 0.003266063953271323, 0.003264623150042583, 0.0032574525343647687, 0.0032554566483761413, 0.0032469489216929845, 0.003221900764006912, 0.00322009677279812, 0.0032188554098948117, 0.003213676336398458, 0.003203185066256121, 0.0032028704937202765, 0.003202477356378069, 0.0032013463739989922, 0.0031993736667770114, 0.0031844856085940206, 0.0031794973692356268, 0.0031734486554060278, 0.0031714734986125555, 0.003164061797183951, 0.003163395091198844, 0.0031588658268241615, 0.00315423510948997, 0.003142661092290254, 0.0031426130154738685, 0.0031398801524981173, 0.0031368675705800587, 0.0031351794281550154, 0.003120549372825703, 0.0031183054001673286, 0.0031142553700972252, 0.0031077986298081914, 0.003106842014515369, 0.0030987208167099394, 0.0030844046925139557, 0.003079276530829313, 0.0030698944835991534, 0.0030687487045722014, 0.0030660654494272487, 0.0030651752513351825, 0.003065067292181829, 0.0030539608116236074, 0.003051439124684057, 0.003045977789485523, 0.0030423253535488606, 0.003035344918363632, 0.0030231057281032304, 0.0030176659570688574, 0.003015752981642915, 0.00301245735418134, 0.0030090575084269025, 0.003009032761484025, 0.0030066441749937653, 0.003001351323801621, 0.0029975870382870076, 0.0029937871345473758, 0.002987570594764886, 0.00298448040878281, 0.0029721043037606587, 0.002951537055140626, 0.00294895766695285, 0.0029476378559093793, 0.002943150449560032, 0.002942175961985075, 0.00294155444796017, 0.0029413236097312325, 0.002938504297029481, 0.0029372130819625207, 0.0029363683877336325, 0.002932418638022961, 0.002931332075803861, 0.0029248452530479373, 0.0029214243586579555, 0.0029046660445052777, 0.002895160127143033, 0.002879181437662371, 0.0028763851396147832, 0.002865242198045509, 0.0028642151420348694, 0.0028641383399441826, 0.002861183716523587, 0.0028574714808948976, 0.002855941687098895, 0.002854647425252907, 0.0028513120231689402, 0.0028343468345168677, 0.002828051332249646, 0.0028214570019552986, 0.002811816146594949, 0.002807713485869113, 0.0028066701187124043, 0.00280453020119101, 0.002795952820143316, 0.00279120508644768, 0.0027797711554832863, 0.002774897260558988, 0.002772508616024757, 0.0027457005554966966, 0.002741357157186511, 0.002737700103633784, 0.0027238793286670595, 0.0027223460274077987, 0.0027197962549074806, 0.002716898464975194, 0.0027077286731404244, 0.0027069951226978677, 0.0027054003191496877, 0.0027034278674088, 0.0026925568992255686, 0.0026921381467195585, 0.0026905720287755145, 0.0026818187994482254, 0.002677822113641614, 0.002675338089417541, 0.002666833218304226, 0.0026594562110086603, 0.0026456539797933896, 0.002636213346924682, 0.0026226226443555245, 0.0026202262204799882, 0.0026166304245964166, 0.002613132824512158, 0.0026106264163395336, 0.00259876768659883, 0.002598732141386443, 0.0025934886447163247, 0.0025858859649728603, 0.0025839267210646835, 0.0025756324525413876, 0.0025655707281281087, 0.002563891437299432, 0.0025594752041253215, 0.002557093542131563, 0.0025569769950560075, 0.0025564273147843175, 0.00255622129750078, 0.002547959488476729, 0.0025434774677289642, 0.0025393656511088917, 0.0025306291047536324, 0.002522951719761233, 0.0025227274415835005, 0.0025199780573609163, 0.002511120283116334, 0.0025109566935543897, 0.0025075452820972023, 0.0024957050082613885, 0.002491591032148119, 0.002489122188306705, 0.0024856549870716374, 0.0024768993163416697, 0.0024701668637776217, 0.0024693737434590374, 0.0024656166209056263, 0.002459625438469743, 0.0024533447889092115, 0.0024510166514147887, 0.002449050312492008, 0.0024384725772326242, 0.0024365642523653105, 0.0024354599496527215, 0.002428893740773115, 0.002427174619150887, 0.0024259911728870226, 0.0024248468135391605, 0.0024228476319424425, 0.0024227511525826504, 0.0024183602482067018, 0.002417184447471578, 0.002393145418506663, 0.0023887420092159987, 0.0023782530722851166, 0.0023712433799119976, 0.0023705336862075493, 0.0023680486043806312, 0.0023672576360193403, 0.002364770192651505, 0.002356901892260471, 0.0023544281570964283, 0.002352673530682199, 0.0023524857743840956, 0.0023198314686009762, 0.002317363740074304, 0.0023160525969433943, 0.002312683590827912, 0.0023095695525500873, 0.0023082529160451874, 0.0023077763410655093, 0.0023041278799184476, 0.00230130733741478, 0.0022789073647741737, 0.0022742173928022797, 0.002266561653667727, 0.0022663623161645104, 0.0022630397566183636, 0.0022615688285722267, 0.0022607704462151088, 0.002258808244971457, 0.0022508275927909244, 0.0022470977628664965, 0.0022448496092190504, 0.0022433289835639067, 0.0022391958991337677, 0.002236291160330022, 0.002235617159606398, 0.002221134212781215, 0.0022162944191620455, 0.0022147139876695673, 0.0022121806946852176, 0.0022006967484536834, 0.00219997118383595, 0.0021861446173788057, 0.002179804524694309, 0.0021788633449419587, 0.0021663176897101567, 0.002162572191827517, 0.0021600962691646257, 0.0021474902966611554, 0.0021435386412837574, 0.002132727570704371, 0.002128000580054332, 0.002123621072842656, 0.002120588740656594, 0.002120435652213526, 0.002116934508656983, 0.002112213923152166, 0.0020950004282574005, 0.002081152450115912, 0.0020803622186491557, 0.0020796578778258944, 0.002078936665350079, 0.002066495004398854, 0.0020662387311500942, 0.0020622526411591523, 0.0020565857136706223, 0.0020506471089021257, 0.0020492805541874252, 0.0020436515115098094, 0.0020407051527655973, 0.0020404278656332418, 0.002032549152844661, 0.0020222673275327296, 0.002021849440942035, 0.0020150406337224006, 0.002004927915787349, 0.002001911922315457, 0.001996722674508901, 0.0019869204581506325, 0.001982404207568068, 0.001982003139887387, 0.0019769158639252504, 0.0019715846304918187, 0.0019686389461320403, 0.0019635562158833893, 0.0019626980553817262, 0.0019565852083804343, 0.0019417892401400907, 0.0019409719541080674, 0.0019308093162439754, 0.0019303790364125148, 0.001915260224475676, 0.0019135750941210617, 0.0019014130225380682, 0.0018944626156830388, 0.0018687835847196938, 0.0018630184489155362, 0.0018616890184557536, 0.0018608807858510727, 0.0018606234866207934, 0.0018536169189641068, 0.0018495823465666573, 0.0018478568807439736, 0.0018333832852257003, 0.0018269572335109633, 0.001821106822523964, 0.001820603193758165, 0.0018119111741711853, 0.0018070724889764002, 0.0018028636619644915, 0.0018026730753025707, 0.0017989072107955535, 0.0017863097298512712, 0.0017861534058038165, 0.0017827481968624881, 0.0017717421003748215, 0.001771636589996833, 0.0017713518287688964, 0.001766060556522289, 0.0017580973517205454, 0.0017575684849546374, 0.001752647531688576, 0.0017511330435492347, 0.0017490126288425122, 0.0017384951019150689, 0.0017373168264548616, 0.001733404640784321, 0.001725727302275047, 0.001716314697532826, 0.0017120964228644875, 0.001703372351201719, 0.0016990579293116215, 0.0016949840914657328, 0.0016883190547384982, 0.0016861039670320534, 0.001684908646316902, 0.0016785000589215632, 0.00167740537150968, 0.0016687378511580702, 0.0016657213623373368, 0.001661453366891603, 0.0016612515109767133, 0.0016588271007560848, 0.001656606333947881, 0.0016528105153680575, 0.0016505326072960022, 0.001648241472040042, 0.0016436872461774693, 0.0016382068404309947, 0.0016352981246401939, 0.00162676906130053, 0.0016155441686183907, 0.0016124065343666154, 0.0016065525439280062, 0.0016063785684882165, 0.0016001171045412314, 0.0015975977800854091, 0.0015906377691782517, 0.0015873201811688116, 0.0015846626408489478, 0.0015813842224864428, 0.0015715009507422423, 0.0015627370603207586, 0.0015533812122064047, 0.001538481231989037, 0.0015363572474973528, 0.001535174538109823, 0.001518092089694289, 0.0015116031868894957, 0.0014934675698449202, 0.0014844923608759498, 0.0014801939732767982, 0.0014708932174567623, 0.001469395909416528, 0.0014691211367484818, 0.0014674246050584861, 0.0014668550932658503, 0.0014640325182383874, 0.0014539357472309414, 0.0014502881162501615, 0.0014452627635447622, 0.0014445652486963668, 0.0014422179534535136, 0.0014415035257016665, 0.0014409283778276977, 0.0014398407764040805, 0.0014374941118022117, 0.0014342541601902572, 0.0014257665071392514, 0.001425384164669604, 0.0014176834520708646, 0.0014153624620820472, 0.0014145665263183243, 0.0014096011118174593, 0.0014027991857813785, 0.0014015222242794935, 0.0013996987473884291, 0.0013907857403246751, 0.0013898949845822922, 0.0013701985738188694, 0.001363362821820759, 0.0013612147278866252, 0.0013530257374718027, 0.001352555205281727, 0.0013484503202707237, 0.001343899954312099, 0.0013416547362356409, 0.0013131270083772367, 0.0013124824386975147, 0.0013027825957578512, 0.001300378105222661, 0.00129653903315246, 0.0012887498599553043, 0.0012831505981377416, 0.001282716235679941, 0.0012549171259066106, 0.0012535217509166358, 0.0012435934983165183, 0.0012432694705682957, 0.0012404026523498268, 0.0012349436027522202, 0.0012301644600377503, 0.0012291219786260705, 0.0012203775055627465, 0.001219180746683229, 0.0012184221248676926, 0.0012010498943933986, 0.0011946057460016878, 0.0011881859387485039, 0.001182105326579799, 0.0011801021691664026, 0.0011791296090580986, 0.0011597821056236056, 0.0011595244101845561, 0.0011592866827791347, 0.0011494984366085476, 0.0011449605419798924, 0.0011346966960959777, 0.0011338728398730302, 0.0011261177825359586, 0.0011218896218007797, 0.0011146362870852917, 0.0011035374861752484, 0.0011017094749183841, 0.001100732103415812, 0.001098548961525678, 0.0010981008441716884, 0.00109646700544036, 0.0010819110487772857, 0.0010725576165111087, 0.0010721348903120634, 0.0010707778671043499, 0.0010522894488969937, 0.0010448409004673392, 0.001042698584317088, 0.001035227483204415, 0.0010349930734988918, 0.0010286685789454597, 0.0010267026631697645, 0.0010244015800465506, 0.0010136014655059919, 0.0010124181961392949, 0.00100636693150663, 0.001004215864255257, 0.0010039657134283517, 0.0010038756827090275, 0.0010009211242077683, 0.0010000933728641732, 0.000984112094217455, 0.0009765887904571715, 0.0009749473067099694, 0.0009738515584496454, 0.0009696587219449386, 0.0009597453855116989, 0.0009374421330310417, 0.0009299672524628896, 0.0009292072041942979, 0.0009198212948265133, 0.0009197693783492212, 0.0009057708572818699, 0.0009050651969566303, 0.0009048240305581331, 0.0008890485784038382, 0.0008773597003038563, 0.0008754120400758812, 0.0008731489796931583, 0.000869722990925525, 0.0008672153794216072, 0.0008604148445353194, 0.0008561392444806088, 0.0008484045057925017, 0.0008481469607787592, 0.0008423328809975821, 0.0008367079065877186, 0.0008242832625334407, 0.0008215925441482499, 0.0008159455135601514, 0.0008150996926481949, 0.0008140232729687843, 0.0008133910982524369, 0.0008115620883394523, 0.0008103894635336323, 0.0008092284279924779, 0.0008031896708863789, 0.0008025059984777959, 0.0007877642648535954, 0.0007845143663485119, 0.0007815437268835278, 0.0007801197349883436, 0.0007732928056531598, 0.0007721362586470162, 0.0007708091381373886, 0.0007629399099144184, 0.0007628689529498955, 0.0007575586116369247, 0.0007520696283962957, 0.0007490924525242323, 0.0007457552154788888, 0.0007397034177531642, 0.0007384248328874337, 0.0007373238290079859, 0.0007364963249217185, 0.0007230687316905171, 0.0007211848695181125, 0.000715292976761933, 0.0007131995638156064, 0.0007094143151435345, 0.000707793404406116, 0.0007065447974746149, 0.00070499040881317, 0.0007043528778170246, 0.0007030694493558469, 0.0007012252962403285, 0.0007010919901364661, 0.0006992200190053893, 0.0006833034434084272, 0.0006824864504679277, 0.0006796533388224024, 0.0006766601514807666, 0.0006730759690149858, 0.0006717722842927262, 0.0006705303518476569, 0.0006680317590578683, 0.0006666022686937276, 0.0006655738251307796, 0.0006620516966728896, 0.0006542801545806345, 0.0006504236344412717, 0.0006486339577271503, 0.0006422415462286588, 0.0006376778793730848, 0.0006289207098826009, 0.0006283487614444957, 0.0006276035690015908, 0.0006180658515716098, 0.0006165541053213971, 0.000615655262884923, 0.0006122068144945254, 0.0006007883816516655, 0.0006000754216524176, 0.0005995810537210463, 0.000594623372290864, 0.0005907053486155662, 0.0005904782958365804, 0.0005818386024605555, 0.000570956613562574, 0.0005653095028032352, 0.0005549876861092935, 0.0005522912260816621, 0.0005506490705355284, 0.0005365217332998351, 0.0005359035314471236, 0.0005346338352886985, 0.0005265763415301607, 0.0005221507323689698, 0.0005220664474781648, 0.0005206376477421244, 0.0005126998654431522, 0.0005125704445648003, 0.0005125270898842145, 0.0005111764318582034, 0.0005043210489237754, 0.0005027393391903595, 0.0005003691553416107, 0.0004985483968815978, 0.00048669990721882697, 0.00048510185812294005, 0.00048356050774773455, 0.00048051864838769226, 0.00047977584138671756, 0.00047485477817819655, 0.00047482801699452715, 0.0004683487372803627, 0.0004628621665364551, 0.0004594992137910728, 0.0004566419625192428, 0.0004539161183312729, 0.0004529123885868073, 0.0004528824818106143, 0.0004505830845254069, 0.00044810008924832086, 0.00044425346480939267, 0.00044327867696383587, 0.0004423272373566953, 0.0004404832717782744, 0.00043722251285708896, 0.00043561415651167663, 0.00043364290624064105, 0.00043108100322936674, 0.00042616329632494355, 0.0004260686214435781, 0.0004204592335323323, 0.00041839397538108236, 0.0004178380341015837, 0.00041310598390045675, 0.00040180557709054937, 0.00040057138517938704, 0.0003983352714867877, 0.0003902007132434161, 0.00037390109887968357, 0.00035909496942064534, 0.0003588795827002624, 0.0003587769544776197, 0.00035654420929926285, 0.0003543858037076671, 0.0003486308634623168, 0.0003350240484957799, 0.0003167037013018897, 0.00030671548301040933, 0.00029428040661148597, 0.00029194206492196104, 0.00029123093648645426, 0.00029029165246890456, 0.0002870834571374461, 0.0002816073048575588, 0.0002785388979186026, 0.00027846482270788974, 0.00027111695197853, 0.0002675478754356691, 0.0002665792114592304, 0.00026252988692644934, 0.00026212054216003547, 0.00025736870842489476, 0.00025652050039669147, 0.00025397473927415683, 0.00025236001470579277, 0.0002478702811754815, 0.00024618202701496644, 0.0002413793955880498, 0.0002413470139862412, 0.00024020135969990997, 0.00023149053462111538, 0.00023084171003052734, 0.00021800293118460497, 0.00019790057346871326, 0.00019680617347280245, 0.00019543265289492069, 0.0001873438475938825, 0.0001858711993472458, 0.00018346529660615086, 0.00017899308559580785, 0.0001639650191827715, 0.00016354333750696735, 0.000160861401049295, 0.00015749371906400547, 0.00015684291294656681, 0.00015479826381988512, 0.0001435035257279609, 0.00013974512703052118, 0.00013690070455673941, 0.00012852568755270864, 0.00012802278747716292, 0.00012381905687904412, 0.00012196084875191622, 0.00011574156250369205, 0.0001134234850544692, 0.0001129969770802577, 0.00011240642837539593, 0.0001094853606497932, 0.00010826405801597854, 0.00010806263823372051, 0.00010631656997486635, 0.00010030180890703528, 9.856553423122951e-05, 9.622319619877114e-05, 9.11355927587371e-05, 7.932140610310108e-05, 7.454080021122088e-05, 7.315352072270067e-05, 7.150947306274437e-05, 5.4802957807407004e-05, 5.382682407545898e-05, 5.234383690900041e-05, 5.026215044839953e-05, 4.4550523668131114e-05, 4.4404163427640246e-05, 4.14604759779212e-05, 4.036097271046342e-05, 3.680001068796291e-05, 3.5271618379522645e-05, 3.2128965749435346e-05, 3.175587822923319e-05, 2.9934881247264718e-05, 2.7849610073560677e-05, 2.77028730547325e-05, 2.6394344326324802e-05, 2.064877270331099e-05, 1.8943151358787494e-05, 9.715156389768426e-06, 6.7746121846507505e-06, 4.598420185741921e-06, 4.429689582268399e-06, 1.8140701713355642e-06]\n"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in range(len(X_test)):\n",
    "    X_out = new_model(X_test[i].float())\n",
    "    # print(X_out)\n",
    "    Y_out= y_test[i]\n",
    "    # print(Y_out)\n",
    "    array.append((sum((X_out - Y_out)**2)).item())\n",
    "    # array.append(loss_fn(X_out, Y_out).item())\n",
    "print(sorted(array)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.sort()\n",
    "array[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008284977062343048"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, f'./model_freezes/{datestring}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240508-153538'"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
